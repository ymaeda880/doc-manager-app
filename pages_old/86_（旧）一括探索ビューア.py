# pages/50_ä¸€æ‹¬æ¢ç´¢ãƒ“ãƒ¥ãƒ¼ã‚¢.py
# ============================================
# ğŸ“ docs_root ä¸€æ‹¬æ¢ç´¢ãƒ“ãƒ¥ãƒ¼ãƒ¯
# - PATHS.docs_root ã‚’èµ·ç‚¹ã«å†å¸°èµ°æŸ»
# - ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ / ã‚µã‚¤ã‚º / å½¢å¼ / æ›´æ–°æ—¥æ™‚ï¼‰
# - å½¢å¼åˆ¥ã‚µãƒãƒªã€ãƒ•ã‚©ãƒ«ãƒ€åˆ¥ã‚µãƒãƒª
# - CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
# ============================================

from __future__ import annotations
from pathlib import Path
from typing import Iterator, Dict, Any, List, Tuple
import os
import sys
import traceback
import datetime as dt

import streamlit as st
import pandas as pd

# æ¨™æº–ãƒ‘ã‚¹
from lib.app_paths import PATHS  # PATHS.docs_root ã‚’ä½¿ç”¨

# docsãƒ‘ã‚¹
docs_root = Path(st.text_input("docs_root", value=str(PATHS.docs_root))).expanduser().resolve()

# ---------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ----------

def _format_bytes(n: int) -> str:
    # ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒªãƒ¼ãƒ€ãƒ–ãƒ«è¡¨è¨˜
    units = ["B", "KB", "MB", "GB", "TB"]
    s = float(n)
    for u in units:
        if s < 1024.0 or u == units[-1]:
            return f"{s:.2f} {u}"
        s /= 1024.0
    return f"{n} B"

def _iter_files(root: Path, ignore_hidden: bool = True) -> Iterator[Path]:
    """root é…ä¸‹ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ yieldï¼ˆã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã¯è¾¿ã‚‰ãªã„ï¼‰"""
    # root ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©º
    if not root.exists():
        return
    for p in root.rglob("*"):
        try:
            if p.is_symlink():
                continue
            if ignore_hidden and any(part.startswith(".") for part in p.relative_to(root).parts):
                continue
            if p.is_file():
                yield p
        except Exception:
            # ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯ãªã©ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue

def _safe_stat(p: Path) -> Tuple[int, float]:
    """ã‚µã‚¤ã‚ºã¨ mtime ã‚’è¿”ã™ï¼ˆå¤±æ•—æ™‚ã¯ 0, 0.0ï¼‰"""
    try:
        st_ = p.stat()
        return int(st_.st_size), float(st_.st_mtime)
    except Exception:
        return 0, 0.0

def _ext_of(p: Path) -> str:
    e = p.suffix.lower().strip()
    return e[1:] if e.startswith(".") else e  # ".PDF" -> "pdf"

# ---------- Streamlit UI ----------

st.set_page_config(page_title="Docs Explorer", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ Docs Explorer â€” docs_root é…ä¸‹ã®ä¸€æ‹¬ä¸€è¦§")

with st.sidebar:
    st.header("è¨­å®š")
    
    st.caption(f"å®Ÿãƒ‘ã‚¹: `{docs_root}`")

    col = st.columns(2)
    with col[0]:
        ignore_hidden = st.checkbox("éš ã—ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ•ã‚©ãƒ«ãƒ€ã‚’é™¤å¤–", value=True)
    with col[1]:
        max_rows = st.number_input("è¡¨ç¤ºä»¶æ•°ï¼ˆå…ˆé ­Nï¼‰", min_value=100, max_value=200_000, value=10_000, step=100)

    st.divider()
    st.subheader("ãƒ•ã‚£ãƒ«ã‚¿")
    name_filter = st.text_input("ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚€æ–‡å­—ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", value="").strip()
    ext_filter  = st.text_input("æ‹¡å¼µå­ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆä¾‹: pdf,docx,xlsx ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰", value="").strip()
    folder_filter = st.text_input("ç›¸å¯¾ãƒ•ã‚©ãƒ«ãƒ€ã«å«ã‚€æ–‡å­—ï¼ˆä¾‹: 2025/reportsï¼‰", value="").strip()

    st.divider()
    st.subheader("ä¸¦ã³é †")
    sort_by = st.selectbox("ã‚½ãƒ¼ãƒˆã‚­ãƒ¼", ["path", "size", "mtime", "ext"], index=0)
    ascending = st.checkbox("æ˜‡é †", value=True)

# ---------- ãƒ‡ãƒ¼ã‚¿åé›† ----------

if not docs_root.exists():
    st.error("docs_root ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚è¨­å®šã¾ãŸã¯ãƒã‚¦ãƒ³ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

rows: List[Dict[str, Any]] = []
root = docs_root

try:
    for p in _iter_files(root, ignore_hidden=ignore_hidden):
        size, mtime = _safe_stat(p)
        rel = str(p.relative_to(root))
        ext = _ext_of(p)
        if name_filter and (name_filter.lower() not in p.name.lower()):
            continue
        if folder_filter and (folder_filter.lower() not in rel.lower()):
            continue
        if ext_filter:
            allow = {e.strip().lower() for e in ext_filter.split(",") if e.strip()}
            if ext not in allow:
                continue
        rows.append({
            "path": rel,
            "name": p.name,
            "ext": ext or "(none)",
            "size": size,
            "size_hr": _format_bytes(size),
            "mtime": mtime,
            "modified": dt.datetime.fromtimestamp(mtime) if mtime else None,
            "parent": str(p.parent.relative_to(root)) if p.parent != root else "",
            "depth": len(p.relative_to(root).parts) - 1,
        })
        if len(rows) >= int(max_rows):
            # å–ã‚Šã™ãé˜²æ­¢ï¼ˆè¡¨ç¤ºç”¨ï¼‰
            break
except Exception as e:
    st.error(f"èµ°æŸ»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    with st.expander("ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹"):
        st.code(traceback.format_exc())

if not rows:
    st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

df = pd.DataFrame(rows)

# ã‚½ãƒ¼ãƒˆ
if sort_by == "path":
    df = df.sort_values("path", ascending=ascending, kind="mergesort")
elif sort_by == "size":
    df = df.sort_values("size", ascending=ascending, kind="mergesort")
elif sort_by == "mtime":
    df = df.sort_values("mtime", ascending=ascending, kind="mergesort")
elif sort_by == "ext":
    df = df.sort_values(["ext", "path"], ascending=[ascending, True], kind="mergesort")

# ---------- ã‚µãƒãƒª ----------

st.subheader("ğŸ“Š ã‚µãƒãƒª")
c1, c2, c3, c4 = st.columns(4)
c1.metric("ãƒ•ã‚¡ã‚¤ãƒ«æ•°", f"{len(df):,}")
c2.metric("ç·ã‚µã‚¤ã‚º", _format_bytes(int(df["size"].sum())))
unique_exts = df["ext"].nunique()
c3.metric("å½¢å¼ï¼ˆæ‹¡å¼µå­ï¼‰æ•°", f"{unique_exts:,}")
top_ext = df["ext"].value_counts().head(1)
c4.metric("æœ€å¤šå½¢å¼", f"{top_ext.index[0]}ï¼ˆ{top_ext.iloc[0]:,}ä»¶ï¼‰" if not top_ext.empty else "-")

with st.expander("æ‹¡å¼µå­åˆ¥ã‚µãƒãƒªï¼ˆä»¶æ•°ãƒ»åˆè¨ˆã‚µã‚¤ã‚ºï¼‰", expanded=True):
    ext_summary = (
        df.groupby("ext")
          .agg(count=("path", "count"), total_size=("size", "sum"))
          .reset_index()
          .sort_values(["count", "ext"], ascending=[False, True])
    )
    ext_summary["total_size_hr"] = ext_summary["total_size"].map(lambda x: _format_bytes(int(x)))
    st.dataframe(ext_summary, width="stretch")
    st.download_button(
        "â¬‡ï¸ æ‹¡å¼µå­ã‚µãƒãƒªã‚’CSVã§ä¿å­˜",
        data=ext_summary.to_csv(index=False).encode("utf-8"),
        file_name="ext_summary.csv",
        mime="text/csv",
    )

with st.expander("ãƒ•ã‚©ãƒ«ãƒ€åˆ¥ã‚µãƒãƒªï¼ˆç›´ä¸Šè¦ªãƒ•ã‚©ãƒ«ãƒ€å˜ä½ï¼‰", expanded=False):
    folder_summary = (
        df.groupby("parent")
          .agg(count=("path", "count"), total_size=("size", "sum"))
          .reset_index()
          .sort_values(["count", "parent"], ascending=[False, True])
    )
    folder_summary["total_size_hr"] = folder_summary["total_size"].map(lambda x: _format_bytes(int(x)))
    st.dataframe(folder_summary, width="stretch")
    st.download_button(
        "â¬‡ï¸ ãƒ•ã‚©ãƒ«ãƒ€ã‚µãƒãƒªã‚’CSVã§ä¿å­˜",
        data=folder_summary.to_csv(index=False).encode("utf-8"),
        file_name="folder_summary.csv",
        mime="text/csv",
    )

st.divider()

# ---------- ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ ----------

st.subheader("ğŸ—‚ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
show_cols = ["path", "name", "ext", "size_hr", "modified", "parent", "depth"]
st.dataframe(df[show_cols], width="stretch", height=520)

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰
st.download_button(
    "â¬‡ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’CSVã§ä¿å­˜ï¼ˆå…¨åˆ—ï¼‰",
    data=df.to_csv(index=False).encode("utf-8"),
    file_name="docs_files.csv",
    mime="text/csv",
)

st.caption("â€» è¡¨ç¤ºä»¶æ•°ãŒå¤šã„å ´åˆã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œè¡¨ç¤ºä»¶æ•°ï¼ˆå…ˆé ­Nï¼‰ã€ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
