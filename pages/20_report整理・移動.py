"""
pages/20_reportæ•´ç†.py
============================================
ğŸ“‚ report æ•´ç†ï¼ˆoriginal_docs_root/report é…ä¸‹ã®ä¸€è¦§ï¼‰

ã“ã®ãƒšãƒ¼ã‚¸ã§ã§ãã‚‹ã“ã¨ï¼ˆå‡¦ç†ã®æµã‚Œï¼‰
------------------------------------
â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ï¼ˆ`original_docs_root/report` ç›´ä¸‹ã®ã¿ï¼‰
    - éš ã—ãƒ•ã‚©ãƒ«ãƒ€ã®é™¤å¤–ã‚„ã€ç›´ä¸‹ files/dirs ä»¶æ•°ã®å–å¾—ã‚’é¸æŠå¯èƒ½
    - ä¸€è¦§ã¯ DataFrame ã§è¡¨ç¤º

â‘¡ ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¦å‰‡ã§ã€Œå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã€ã«åˆ†é¡
    - 7æ¡æ•°å€¤: `YYYYPPP`ï¼ˆYYYY=å¹´, PPP=ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ï¼‰
    - `HNNPPP`: å¹³æˆ â†’ è¥¿æš¦ã¯ `1988 + NN`
    - `SNNPPP`: æ˜­å’Œ â†’ è¥¿æš¦ã¯ `1925 + NN`
    - `P...`   : å›³æ›¸é¤¨ç®¡ç†ï¼ˆå¹´=9999, PNo=999ï¼‰ã¨ã—ã¦ä¸€æ—¦ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€
    - ä¸Šè¨˜ä»¥å¤–ã¯ `other` ã¨ã—ã¦å¹´ãªã—
    - â˜… å¹´ã”ã¨ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸ã€‚
      ã“ã“ã§ãƒã‚§ãƒƒã‚¯ã—ãŸ **å¹´** ã‚’ â‘£ ã®å¯¾è±¡å¹´ã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚

â‘¢ Library(P) ãƒ•ã‚©ãƒ«ãƒ€ â†’ å›³æ›¸ç®¡ç†DBï¼ˆExcel: Sheet1ï¼‰ã§å¹´ã‚’è£œè¶³åˆ†é¡
    - Library(P) ãƒ•ã‚©ãƒ«ãƒ€å†…ã® PDFï¼ˆç›´ä¸‹ã®ã¿å¯¾è±¡ï¼‰ã«ã¤ã„ã¦
      å…ˆé ­ã€Œç™»éŒ²ç•ªå·-â€¦â€¦ã€ã‹ã‚‰ã€Œç™»éŒ²ç•ªå·ã€ã‚’å–ã‚Šå‡ºã—ã€DB ã§ã€Œç™ºè¡Œå¹´ã€ã‚’æ¤œç´¢
    - ç™ºè¡Œå¹´ã®è¡¨è¨˜ã‚†ã‚Œï¼ˆ1981/3, 1977.2, å…¨è§’æ•°å­—ç­‰ï¼‰ã‚’æ­£è¦åŒ–ã—ã¦ 4 æ¡å¹´ã«æ•´å½¢
    - å–å¾—ã§ããªã„ or ä¸æ­£ã¯ `9999` ã¨ã™ã‚‹
    - â˜… å¹´ã”ã¨ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸ï¼ˆé¸æŠçŠ¶æ…‹ã¯ä¿å­˜ã€‚å‡¦ç†ã¯å¾Œã§è¿½åŠ ï¼‰ã€‚

â‘£ â‘¡ã§é¸æŠã—ãŸå¹´ â†’ <ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/ ã¸ PDF ã‚³ãƒ”ãƒ¼
    - â‘¡ã§ãƒã‚§ãƒƒã‚¯ã—ãŸã€Œå¹´ã€ã ã‘ã‚’å¯¾è±¡
    - å¯¾è±¡ã‚½ãƒ¼ã‚¹: ãã®å¹´ã® **7æ¡æ•°å€¤ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆYYYYPPPï¼‰**
    - ã‚³ãƒ”ãƒ¼å…ˆ: `<ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/`ï¼ˆä¾‹: `ExtremeSSD/report/pdf/2020/123/`ï¼‰
    - æ—¢å­˜åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
"""

from __future__ import annotations
from pathlib import Path
from typing import Iterator, Dict, Any, List
import os
import re
import shutil
import datetime as dt

import streamlit as st
import pandas as pd

from lib.app_paths import PATHS
from lib.fsnav.scan import iter_dirs, safe_stat_mtime, listdir_counts

# ä»»æ„ï¼šPDFã®è»½é‡ç¨®åˆ¥ï¼ˆç¾çŠ¶æœªä½¿ç”¨ã§ã‚‚OKï¼‰
try:
    from lib.pdf.info import quick_pdf_info  # noqa: F401
except Exception:
    quick_pdf_info = None

import sys
from pathlib import Path

# projects/ ã‚’ import ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆpages â†’ app â†’ project â†’ projectsï¼‰
PROJECTS_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECTS_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECTS_ROOT))

# ã“ã‚Œã§ common_lib ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦å‚ç…§ã§ãã‚‹
from common_lib.ui.ui_basics import thick_divider

# import _bootstrap_path
# from common_lib.ui.ui_basics import thick_divider


# ========== ãƒšãƒ¼ã‚¸è¨­å®š ==========
st.set_page_config(page_title="report æ•´ç†", page_icon="ğŸ“‚", layout="wide")



st.title("ğŸ“‚ report æ•´ç† â€” original_docs_root/report é…ä¸‹ã®ä¸€è¦§")

st.info("ä½¿ç”¨ãƒ«ãƒ¼ãƒˆï¼šoriginal_docs_root -> organized_docs_root")



# â˜… ã“ã“ã«ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’è¿½åŠ 
try:
    org_root = Path(PATHS.original_docs_root).expanduser().resolve()
    orgz_root = Path(PATHS.organized_docs_root).expanduser().resolve()
    st.markdown(
        f"""
        **original_docs_root:** `{org_root}`  
        **organized_docs_root:** `{orgz_root}`
        """,
        unsafe_allow_html=True,
    )
except Exception as e:
    st.warning(f"ãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

st.markdown(
    """
    <span style="color:steelblue;">
    å…ƒæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆoriginal_docsï¼‰ã‚’ä½œæ¥­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆorganized_docsï¼‰ã«æ•´ç†ã—ã¦ã‚³ãƒ”ãƒ¼ã—ã¾ã™ã€‚<br>    
    ä½œæ¥­ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’ã€å¹´ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã”ã¨ã«ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã‚’ä½œã£ã¦æ ¼ç´ã—ã¾ã™ã€‚
    </span>
    """,
    unsafe_allow_html=True
)



thick_divider(color="Blue", height=3, margin="1.5em 0")

st.markdown("""
### ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¦å‰‡ã§ã€Œå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã€ã«åˆ†é¡
- 7æ¡æ•°å€¤: `YYYYPPP`ï¼ˆYYYY=å¹´, PPP=ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ï¼‰  
- `HNNPPP`: å¹³æˆ â†’ è¥¿æš¦ã¯ `1988 + NN`  
- `SNNPPP`: æ˜­å’Œ â†’ è¥¿æš¦ã¯ `1925 + NN`  
- `P...`   : å›³æ›¸é¤¨ç®¡ç†ï¼ˆå¹´=9999, PNo=999ï¼‰ã¨ã—ã¦ä¸€æ—¦ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€  
- ä¸Šè¨˜ä»¥å¤–ã¯ `other` ã¨ã—ã¦å¹´ãªã—  
- â˜… å¹´ã”ã¨ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸ã€‚  
  ã“ã“ã§ãƒã‚§ãƒƒã‚¯ã—ãŸ **å¹´** ã‚’ â‘£ ã®å¯¾è±¡å¹´ã¨ã—ã¦åˆ©ç”¨ã—ã¾ã™ã€‚

---

### é¸æŠã—ãŸå¹´ â†’ `<ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/` ã¸ PDF ã‚³ãƒ”ãƒ¼
- â‘¡ã§ãƒã‚§ãƒƒã‚¯ã—ãŸã€Œå¹´ã€ã ã‘ã‚’å¯¾è±¡  
- å¯¾è±¡ã‚½ãƒ¼ã‚¹: ãã®å¹´ã® **7æ¡æ•°å€¤ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆYYYYPPPï¼‰**  
- ã‚³ãƒ”ãƒ¼å…ˆ: `<ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/`  
  ï¼ˆä¾‹: `ExtremeSSD/report/pdf/2020/123/`ï¼‰  
- æ—¢å­˜åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—
""")

# ========== èµ·ç‚¹ ==========
ROOT_BASE = Path(str(PATHS.original_docs_root)).expanduser().resolve()
REPORT_ROOT_DEFAULT = ROOT_BASE / "report"
report_text = st.text_input("report ã®å®Ÿãƒ‘ã‚¹ï¼ˆå¤‰æ›´ä¸è¦ãªã‚‰æ—¢å®šã®ã¾ã¾ï¼‰", value=str(REPORT_ROOT_DEFAULT))
REPORT_ROOT = Path(report_text).expanduser().resolve()

if not REPORT_ROOT.exists():
    st.error("original_docs_root/report ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PATHS ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ========== ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==========
with st.sidebar:
    st.header("è¨­å®š")
    st.caption(f"å®Ÿãƒ‘ã‚¹: `{REPORT_ROOT}`")
    c = st.columns(2)
    with c[0]:
        ignore_hidden = st.checkbox("éš ã—ãƒ•ã‚©ãƒ«ãƒ€ã‚’é™¤å¤–", value=True)
    with c[1]:
        compute_counts = st.checkbox("ç›´ä¸‹ã®ä»¶æ•°ã‚’è¨ˆç®—", value=False)
    st.divider()
    st.subheader("â‘  ãƒ•ã‚£ãƒ«ã‚¿")
    name_filter = st.text_input("åç§°ã®éƒ¨åˆ†ä¸€è‡´ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ï¼‰", value="").strip()

    st.subheader("â‘ .5 è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    grid_cols = st.slider("æ¨ªã®åˆ—æ•°ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¨ªä¸¦ã³è¡¨ç¤ºï¼‰", min_value=2, max_value=10, value=5, step=1)
    calc_recursive = st.checkbox("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã®**å†å¸°**é›†è¨ˆï¼ˆä»¶æ•°ãƒ»ç·å®¹é‡ï¼‰ã‚’è¨ˆç®—ã™ã‚‹", value=False,
                                 help="ONã«ã™ã‚‹ã¨å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€å†…ã®PDFã«é™ã‚‰ãšå…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°ã§æ•°ãˆã€ç·å®¹é‡ã‚’ç®—å‡ºã—ã¾ã™ã€‚æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")


def _parse_folder_name(name: str) -> Dict[str, Any]:
    """ãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰å¹´/ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·/ã‚«ãƒ†ã‚´ãƒªã‚’æŠ½å‡ºã€‚"""
    # (i) 7æ¡: YYYYPPP
    m = re.fullmatch(r"(\d{4})(\d{3})", name)
    if m:
        return {"name": name, "category": "numeric7", "year": int(m[1]), "pno": int(m[2])}
    # (ii) Heisei: HNNPPP
    m = re.fullmatch(r"H(\d{2})(\d{3})", name, re.I)
    if m:
        return {"name": name, "category": "Heisei", "year": 1988 + int(m[1]), "pno": int(m[2])}
    # (iii) Showa: SNNPPP
    m = re.fullmatch(r"S(\d{2})(\d{3})", name, re.I)
    if m:
        return {"name": name, "category": "Showa", "year": 1925 + int(m[1]), "pno": int(m[2])}
    # (iv) P*
    if re.match(r"^P", name, re.I):
        return {"name": name, "category": "Library(P)", "year": 9999, "pno": 999}
    # (v) ãã®ä»–
    return {"name": name, "category": "other", "year": None, "pno": None}


thick_divider(color="Blue", height=3, margin="1.5em 0")

# ========== â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ ==========
st.subheader("â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ï¼ˆreport ç›´ä¸‹ï¼‰")
st.info(f"""
ï¼ˆåŸæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰original_docs_root: `{org_root}`  
""")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ï¼ˆ`original_docs_root/report` ç›´ä¸‹ã®ã¿ï¼‰
    - éš ã—ãƒ•ã‚©ãƒ«ãƒ€ã®é™¤å¤–ã‚„ã€ç›´ä¸‹ files/dirs ä»¶æ•°ã®å–å¾—ã‚’é¸æŠå¯èƒ½
    - ä¸€è¦§ã¯ DataFrame ã§è¡¨ç¤º 
    """,
    unsafe_allow_html=True
)
rows_lvl1: List[Dict[str, Any]] = []
level1_paths: List[Path] = []

for d in iter_dirs(REPORT_ROOT, max_depth=1, ignore_hidden=ignore_hidden):
    level1_paths.append(d)
    nm = d.name
    if name_filter and (name_filter.lower() not in nm.lower()):
        continue
    mtime = safe_stat_mtime(d)
    fcnt, dcnt = listdir_counts(d) if compute_counts else (None, None)
    rows_lvl1.append({
        "path": str(d.relative_to(REPORT_ROOT)),
        "name": nm,
        "depth": 1,
        "modified": dt.datetime.fromtimestamp(mtime) if mtime else None,
        "files_direct": fcnt,
        "dirs_direct": dcnt,
    })

if rows_lvl1:
    df1 = pd.DataFrame(rows_lvl1).sort_values("path")
    st.dataframe(df1, width="stretch", height=300)
else:
    st.info("ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.divider()

# ========== â‘  å¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ï¼ˆoriginal)ï¼ˆæ‹¡å¼µå­åˆ¥ï¼šä»¶æ•°ãƒ»ç·å®¹é‡ã€å†å¸°ãƒ»DataFrameè¡¨ç¤ºï¼‰ ==========
st.subheader("â‘  å¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ï¼ˆoriginalï¼‰ï¼ˆæ‹¡å¼µå­åˆ¥ï¼šä»¶æ•°ãƒ»ç·å®¹é‡ã€DataFrameè¡¨ç¤ºï¼‰")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - â‘ ã§åˆ—æŒ™ã—ãŸã€Œæ·±ã•1ãƒ•ã‚©ãƒ«ãƒ€ã€ã‚’ **æœ€ä¸‹å±¤ã¾ã§å†å¸°** ã§æœæŸ»ã—ã€**æ‹¡å¼µå­ã”ã¨**ï¼ˆpdf/docx/pptx/xlsxâ€¦ï¼‰ã«**ä»¶æ•°**ã¨**ç·å®¹é‡**ã‚’é›†è¨ˆã—ã¾ã™ã€‚  
    - è¡¨ã®åˆ—é †ã¯ `year / pno / pdf / pdf_size / folder / docx / docx_size / pptx / pptx_size / xlsx / xlsx_size / ...` ã®ä¸¦ã³ã§ã™ã€‚  
    - `folder` åˆ—ã¯å…ƒã®ãƒ•ã‚©ãƒ«ãƒ€åï¼ˆä¾‹: `2019003`ï¼‰ã§ã™ã€‚  
    """,
    unsafe_allow_html=True
)

def _fmt_bytes(n: int | None) -> str:
    if n is None:
        return "â€”"
    units = ["B", "KB", "MB", "GB", "TB"]
    size = float(n)
    idx = 0
    while size >= 1024 and idx < len(units) - 1:
        size /= 1024.0
        idx += 1
    return f"{size:.1f} {units[idx]}"

# é›†è¨ˆå¯¾è±¡ã®ä»£è¡¨æ‹¡å¼µå­ï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ ï¼‰
TARGET_EXTS = ["pdf", "docx", "pptx", "xlsx", "csv", "txt", "jpg", "jpeg", "png"]

@st.cache_data(show_spinner=False)
def _ext_stats_recursive_cached(path_str: str, mtime: float, ignore_hidden: bool) -> dict:
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã‚’å†å¸°ã§èµ°æŸ»ã—ã€æ‹¡å¼µå­ã”ã¨ã®ä»¶æ•°ãƒ»ç·å®¹é‡ã‚’è¿”ã™ã€‚
    è¿”ã‚Šå€¤: {"by_ext": {ext: {"count":int, "bytes":int}}, "total_files":int, "total_bytes":int}
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ path + mtime + ignore_hidden ã‚’ã‚­ãƒ¼ã«ã™ã‚‹ã€‚
    """
    import os
    from pathlib import Path

    p = Path(path_str)
    by_ext: dict[str, dict] = {}
    total_files = 0
    total_bytes = 0

    if not p.exists():
        return {"by_ext": {}, "total_files": 0, "total_bytes": 0}

    for cur, dirs, files in os.walk(p, topdown=True, followlinks=False):
        # éš ã—é™¤å¤–
        dirs[:] = [d for d in dirs if not (ignore_hidden and d.startswith("."))]
        for fn in files:
            if ignore_hidden and fn.startswith("."):
                continue
            total_files += 1
            fpath = Path(cur) / fn
            # ã‚µã‚¤ã‚º
            try:
                sz = fpath.stat().st_size
            except Exception:
                sz = 0
            total_bytes += sz
            # æ‹¡å¼µå­
            ext = fpath.suffix.lower().lstrip(".")
            if not ext:
                ext = "(noext)"
            slot = by_ext.setdefault(ext, {"count": 0, "bytes": 0})
            slot["count"] += 1
            slot["bytes"] += sz

    return {"by_ext": by_ext, "total_files": total_files, "total_bytes": total_bytes}

# === rows_lvl1 ã‚’è§£æã—ã¦ year/pno æŠ½å‡ºï¼ˆnumeric7 / Heisei / Showa ã‚’å¯¾è±¡ï¼‰ ===
parsed_for_grid = []
for row in rows_lvl1:
    info = _parse_folder_name(row["name"])
    if info["category"] in ("numeric7", "Heisei", "Showa"):
        info["path"] = row["path"]
        parsed_for_grid.append(info)

if not parsed_for_grid:
    st.info("å¯¾è±¡ã¨ãªã‚‹ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    records: list[dict] = []
    for item in sorted(parsed_for_grid, key=lambda x: (x["year"], x["pno"])):
        year = item["year"]
        pno = item["pno"]
        folder_name = item["name"]  # ä¾‹: 2019003
        folder_path = (REPORT_ROOT / item["path"]).resolve()

        mtime = safe_stat_mtime(folder_path) or 0.0
        stats = _ext_stats_recursive_cached(str(folder_path), mtime, ignore_hidden=ignore_hidden)
        by_ext = stats["by_ext"]

        rec: dict = {
            "year": year,
            "pno": int(pno) if pno is not None else None,
            "folder": folder_name,
            "relpath": str(folder_path.relative_to(REPORT_ROOT)),
        }

        # ä»£è¡¨æ‹¡å¼µå­ã®åˆ—ã‚’ã€Œä»¶æ•°ã€ã€Œã‚µã‚¤ã‚ºï¼ˆfmtï¼‰ã€ã§ä¸¦ã¹ã‚‹
        for ext in TARGET_EXTS:
            cnt = by_ext.get(ext, {}).get("count", 0)
            bts = by_ext.get(ext, {}).get("bytes", 0)
            rec[f"{ext}"] = cnt
            rec[f"{ext}_size"] = _fmt_bytes(bts)

        # TARGET_EXTS ä»¥å¤–ã‚‚åˆç®—ï¼ˆotherï¼‰
        other_cnt = 0
        other_bts = 0
        for ext, v in by_ext.items():
            if ext not in TARGET_EXTS:
                other_cnt += v.get("count", 0)
                other_bts += v.get("bytes", 0)
        rec["other"] = other_cnt
        rec["other_size"] = _fmt_bytes(other_bts)

        # ãƒˆãƒ¼ã‚¿ãƒ«
        rec["files_total"] = stats["total_files"]
        rec["size_total"] = _fmt_bytes(stats["total_bytes"])

        records.append(rec)

      # åˆ—é †ã‚’æ•´ãˆã‚‹ï¼ˆyear / pno / files_total / size_total / pdf / pdf_size / ... / folder / relpathï¼‰
    cols_order = ["year", "pno", "files_total", "size_total"]
    for ext in TARGET_EXTS:
        cols_order += [ext, f"{ext}_size"]
    cols_order += ["other", "other_size", "folder", "relpath"]

    df_ext = pd.DataFrame(records)

    # æ¬ ã‘åˆ—ãŒã‚ã£ã¦ã‚‚è½ã¡ãªã„ã‚ˆã†ã«è£œå®Œ
    for col in cols_order:
        if col not in df_ext.columns:
            # _sizeåˆ—ãªã‚‰æ–‡å­—åˆ—ã€ä»¶æ•°åˆ—ãªã‚‰0
            if col.endswith("_size") or col in ("size_total",):
                df_ext[col] = "â€”"
            else:
                df_ext[col] = 0

    df_ext = df_ext[cols_order].sort_values(["year", "pno"]).reset_index(drop=True)

    st.dataframe(df_ext, width="stretch", height=520)


# ========== â‘ .6 æ¯”è¼ƒï¼ˆorganizedé…ä¸‹ vs â‘ .5 é›†è¨ˆï¼‰ ==========
st.subheader("â‘ .6 æ¯”è¼ƒï¼ˆorganizedé…ä¸‹ vs â‘ .5 é›†è¨ˆï¼‰")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - ä¸‹è¨˜ã®**ã‚³ãƒ”ãƒ¼å…ˆãƒ™ãƒ¼ã‚¹**ï¼ˆæ—¢å®šï¼š`organized_docs_root/report/pdf`ï¼‰ã‚’èµ·ç‚¹ã«ã€  
      `year/pno` ã¾ãŸã¯ `pno` ç›´ä¸‹æ§‹æˆã‚’**è‡ªå‹•åˆ¤åˆ¥**ã—ã¦æ ¼ç´PDFã‚’é›†è¨ˆã—ã¾ã™ï¼ˆPDFã®ã¿å¯¾è±¡ï¼‰ã€‚  
    - â‘ .5 ã§è¨ˆç®—ã—ãŸ **year/pno ã”ã¨ã® PDF å€‹æ•°ãƒ»å®¹é‡** ã¨æ¯”è¼ƒã—ã€  
      **ä¸€è‡´/ä¸ä¸€è‡´** ã¨ **å·®åˆ†ãƒ•ã‚¡ã‚¤ãƒ«å**ï¼ˆä¸è¶³/ä½™å‰°ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚  
    """,
    unsafe_allow_html=True
)

# â‘£ã®å…¥åŠ›å€¤ã‚’å‚ç…§ã—ã¦ä½¿ã†ï¼ˆâ‘ .6ã§ã¯åŒã˜keyã®å…¥åŠ›ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’æç”»ã—ãªã„ï¼‰
default_dest = str((Path(PATHS.organized_docs_root).expanduser().resolve() / "report" / "pdf"))
if "dest_base_input" not in st.session_state:
    st.session_state["dest_base_input"] = default_dest

dest_base_text_16 = st.session_state["dest_base_input"]
DEST_BASE_16 = Path(dest_base_text_16).expanduser().resolve()
st.caption(f"æ¯”è¼ƒå¯¾è±¡ã® organized ãƒ™ãƒ¼ã‚¹: `{DEST_BASE_16}`")
st.caption(f"æ¯”è¼ƒå…ƒã® original ãƒ™ãƒ¼ã‚¹: `{REPORT_ROOT}`")


# organizedç›´ä¸‹ã«å­˜åœ¨ã™ã‚‹ã€Œå¹´ï¼ˆ4æ¡ï¼‰ãƒ•ã‚©ãƒ«ãƒ€ã€ã‚’åˆ—æŒ™ï¼ˆç„¡ã‘ã‚Œã°ç©ºé›†åˆï¼‰
try:
    AVAILABLE_YEARS = {
        int(p.name)
        for p in DEST_BASE_16.iterdir()
        if p.is_dir() and re.fullmatch(r"\d{4}", p.name)
    }
except Exception:
    AVAILABLE_YEARS = set()


def _fmt_bytes(n: int) -> str:
    units = ["B", "KB", "MB", "GB", "TB"]
    size = float(n)
    idx = 0
    while size >= 1024 and idx < len(units) - 1:
        size /= 1024.0
        idx += 1
    return f"{size:.1f} {units[idx]}"

def _walk_pdfs_under(root: Path, *, ignore_hidden: bool = True) -> tuple[set[str], int]:
    """
    root ä»¥ä¸‹ã® PDFï¼ˆ.pdfï¼‰ã ã‘ã‚’å†å¸°ã§é›†ã‚ã‚‹ã€‚
    ãŸã ã— *_ocr.pdf ã¯ç„¡è¦–ã™ã‚‹ï¼ˆæ¯”è¼ƒå¯¾è±¡å¤–ï¼‰ã€‚
    æˆ»ã‚Šå€¤ï¼š(basenameé›†åˆ, ç·ãƒã‚¤ãƒˆ)
    """
    names: set[str] = set()
    total = 0
    if not root.exists():
        return names, 0
    for cur, dirs, files in os.walk(root, topdown=True, followlinks=False):
        # éš ã—é™¤å¤–
        dirs[:] = [d for d in dirs if not (ignore_hidden and d.startswith("."))]
        for fn in files:
            if ignore_hidden and fn.startswith("."):
                continue
            low = fn.lower()
            # .pdf ã‹ã¤ *_ocr.pdf ã¯é™¤å¤–
            if (low.endswith(".pdf")) and (not low.endswith("_ocr.pdf")):
                names.add(fn)
                try:
                    total += (Path(cur) / fn).stat().st_size
                except Exception:
                    pass
    return names, total

def _resolve_dest_bucket(base: Path, year: int, pno: int) -> Path | None:
    """
    organized å´ã®æ ¼ç´å…ˆã‚’è‡ªå‹•åˆ¤åˆ¥:
      1) base/<year>/<pno:03d>/ ãŒã‚ã‚Œã°æ¡ç”¨
      2) base/<pno:03d>/      ãŒã‚ã‚Œã°æ¡ç”¨ï¼ˆpno ç›´ä¸‹æ§‹æˆï¼‰
      3) ã©ã¡ã‚‰ã‚‚ç„¡ã‘ã‚Œã° None
    """
    y_path = base / str(year) / f"{int(pno):03d}"
    if y_path.exists():
        return y_path
    p_path = base / f"{int(pno):03d}"
    if p_path.exists():
        return p_path
    return None

# â‘ .5 ã§ä½œã£ãŸ parsed_for_gridï¼ˆnumeric7/Heisei/Showaï¼‰ã‚’å‰æã«æ¯”è¼ƒ
if not parsed_for_grid:
    st.info("â‘ .5 ã«å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ãŒç„¡ã„ãŸã‚ã€æ¯”è¼ƒå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    # year,pno ã”ã¨ã«â€œã‚½ãƒ¼ã‚¹â€ã® PDF åŸºæº–é›†åˆã‚’ä½œã‚‹
    #   - â‘ .5 ã§ã¯ by_ext ã®åˆè¨ˆã ã‘ã ã£ãŸã®ã§ã€ã“ã“ã§æ”¹ã‚ã¦ PDF ã‚’**ãƒ•ã‚¡ã‚¤ãƒ«åå˜ä½**ã§åé›†
    buckets_src: dict[tuple[int, int], dict] = {}
    for item in sorted(parsed_for_grid, key=lambda x: (x["year"], x["pno"])):
        year: int = int(item["year"])
        pno:  int = int(item["pno"])
        src_dir = (REPORT_ROOT / item["path"]).resolve()
        names, total_bytes = _walk_pdfs_under(src_dir, ignore_hidden=ignore_hidden)
        rec = buckets_src.setdefault((year, pno), {"names": set(), "bytes": 0, "folders": []})
        rec["names"].update(names)
        rec["bytes"] += total_bytes
        rec["folders"].append(item["name"])  # ä¾‹: 2019003 ãªã©

    # organized å´ã‚’èª¿ã¹ã¦æ¯”è¼ƒ
    rows_cmp: list[dict] = []
    for (year, pno), src in sorted(buckets_src.items()):
        # â˜… organized ã®ç›´ä¸‹ã« year ãƒ•ã‚©ãƒ«ãƒ€ãŒç„¡ã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
        if AVAILABLE_YEARS and (year not in AVAILABLE_YEARS):
            continue
        dest_dir = _resolve_dest_bucket(DEST_BASE_16, year, pno)
        if dest_dir is None:
            # ç½®ãå ´ãªã—
           
            # ç½®ãå ´ãªã—ï¼organized å´ã«å­˜åœ¨ã—ãªã„ã®ã§ã€å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒã€Œä¸è¶³ã€
            _missing_all = sorted(src["names"])
            rows_cmp.append({
                "year": year,
                "pno": pno,
                "src_count": len(src["names"]),
                "src_size": _fmt_bytes(src["bytes"]),
                "src_bytes": src["bytes"],          # â˜…è¿½åŠ 
                "dst_count": 0,
                "dst_size": _fmt_bytes(0),
                "dst_bytes": 0,                      # â˜…è¿½åŠ 
                "match": False,

                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆçŸ­ç¸®ï¼‰
                "missing_in_dst": ", ".join(_missing_all)[:500],
                "extra_in_dst": "",

                # ãƒ•ãƒ«é…åˆ—
                "missing_list": _missing_all,
                "extra_list": [],

                # â˜…å·®åˆ†ä»¶æ•°ï¼ˆå¹´ã‚µãƒãƒªãƒ¼ç”¨ï¼‰
                "missing_count": len(_missing_all),
                "extra_count": 0,

                "dest_path": "(not found)",
                "src_folders": ", ".join(src["folders"]),
            })
            continue

        dst_names, dst_bytes = _walk_pdfs_under(dest_dir, ignore_hidden=ignore_hidden)

        missing = sorted(src["names"] - dst_names)
        extra   = sorted(dst_names - src["names"])

        rows_cmp.append({
            "year": year,
            "pno": pno,
            "src_count": len(src["names"]),
            "src_size": _fmt_bytes(src["bytes"]),
            "src_bytes": src["bytes"],          # â˜…è¿½åŠ 
            "dst_count": len(dst_names),
            "dst_size": _fmt_bytes(dst_bytes),
            "dst_bytes": dst_bytes,             # â˜…è¿½åŠ 
            "match": (len(missing) == 0 and len(extra) == 0 and src["bytes"] == dst_bytes),

            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆçŸ­ç¸®ï¼‰
            "missing_in_dst": ", ".join(missing)[:500],
            "extra_in_dst": ", ".join(extra)[:500],

            # ãƒ•ãƒ«é…åˆ—
            "missing_list": missing,
            "extra_list": extra,

            # â˜…å·®åˆ†ä»¶æ•°ï¼ˆå¹´ã‚µãƒãƒªãƒ¼ç”¨ï¼‰
            "missing_count": len(missing),
            "extra_count": len(extra),

            "dest_path": str(dest_dir),
            "src_folders": ", ".join(src["folders"]),
        })

    # ---- å¹´åˆ¥ PDF æ¯”è¼ƒï¼ˆã‚µãƒãƒªãƒ¼ï¼‰ã‚’å…ˆã«è¡¨ç¤º ----
    df_cmp = pd.DataFrame(rows_cmp)

    if not df_cmp.empty:
        df_year = (
            df_cmp.groupby("year", as_index=False)
            .agg(
                src_count=("src_count", "sum"),
                src_bytes=("src_bytes", "sum"),
                dst_count=("dst_count", "sum"),
                dst_bytes=("dst_bytes", "sum"),
                missing_count=("missing_count", "sum"),
                extra_count=("extra_count", "sum"),
                buckets=("pno", "count"),
                perfect_buckets=("match", "sum"),  # True=1, False=0 ã¨ã—ã¦åˆè¨ˆ
            )
        )
        # èª­ã¿ã‚„ã™ã„ã‚µã‚¤ã‚ºè¡¨è¨˜ã‚’è¿½åŠ 
        df_year["src_size"] = df_year["src_bytes"].map(_fmt_bytes)
        df_year["dst_size"] = df_year["dst_bytes"].map(_fmt_bytes)
        # å¹´å˜ä½ã§ä¸€è‡´åˆ¤å®šï¼šå·®åˆ†ã‚¼ãƒ­ï¼†ç·å®¹é‡ä¸€è‡´
        df_year["match"] = (
            (df_year["missing_count"] == 0)
            & (df_year["extra_count"] == 0)
            & (df_year["src_bytes"] == df_year["dst_bytes"])
        )
        df_year = df_year[
            ["year", "src_count", "src_size", "dst_count", "dst_size",
            "missing_count", "extra_count", "buckets", "perfect_buckets", "match"]
        ].sort_values("year")

        st.markdown("#### å¹´åˆ¥ PDF æ¯”è¼ƒï¼ˆã‚½ãƒ¼ã‚¹ vs organizedï¼‰")
        st.dataframe(df_year, width="stretch", height=240)

        # ===== å¹´ã‚’å…¥åŠ›ã—ã¦ã€Œå‡ºåŠ›ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸæ™‚ã ã‘è©³ç´°ã‚’è¡¨ç¤º =====
        st.markdown("##### å¹´ã‚’æŒ‡å®šã—ã¦è©³ç´°ã‚’å‡ºåŠ›")
        col_y, col_btn = st.columns([2, 1])
        with col_y:
            year_input_str = st.text_input(
                "å¹´ï¼ˆ4æ¡ã€ç©ºæ¬„ãªã‚‰å…¨ä»¶ï¼‰",
                value=st.session_state.get("cmp_year_input", ""),
                key="cmp_year_input"
            )
        with col_btn:
            run_cmp = st.button("â–¶ å‡ºåŠ›", key="cmp_run")

        # ãƒœã‚¿ãƒ³æŠ¼ä¸‹ã§ãƒ•ã‚£ãƒ«ã‚¿å€¤ã‚’ç¢ºå®š
        if run_cmp:
            yf = None
            s = (year_input_str or "").strip()
            if re.fullmatch(r"\d{4}", s):
                yf = int(s)
            st.session_state["cmp_year_filter_val"] = yf
            st.session_state["cmp_run_pressed"] = True

        # ä»¥é™ã®è©³ç´°2è¡¨ã¯ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹å¾Œã®ã¿æç”»
        if st.session_state.get("cmp_run_pressed", False):
            year_filter = st.session_state.get("cmp_year_filter_val", None)

            # --- year/pno ã”ã¨ã® PDF æ¯”è¼ƒ ---
            df_cmp = pd.DataFrame(rows_cmp).sort_values(["year", "pno"]).reset_index(drop=True)
            df_cmp_filtered = df_cmp if year_filter is None else df_cmp[df_cmp["year"] == year_filter]

            st.markdown("#### year/pno ã”ã¨ã® PDF æ¯”è¼ƒï¼ˆã‚½ãƒ¼ã‚¹ vs organizedï¼‰")
            st.dataframe(
                df_cmp_filtered[
                    [
                        "year", "pno",
                        "src_count", "src_size",
                        "dst_count", "dst_size",
                        "match",
                        "missing_in_dst", "extra_in_dst",
                        "src_folders", "dest_path",
                    ]
                ],
                width="stretch",
                height=420,
            )

            # --- å·®åˆ†PDFä¸€è¦§ï¼ˆ1ãƒ•ã‚¡ã‚¤ãƒ«=1è¡Œï¼‰ ---
            diff_rows: list[dict] = []
            for rec in rows_cmp:
                if (year_filter is not None) and (rec.get("year") != year_filter):
                    continue

                year = rec["year"]
                pno  = rec["pno"]
                dest_path = rec.get("dest_path", "")
                src_folders = rec.get("src_folders", "")

                for name in rec.get("missing_list", []):
                    diff_rows.append({
                        "year": year, "pno": pno, "delta": "missing_in_dst",
                        "filename": name, "dest_path": dest_path, "src_folders": src_folders,
                    })
                for name in rec.get("extra_list", []):
                    diff_rows.append({
                        "year": year, "pno": pno, "delta": "extra_in_dst",
                        "filename": name, "dest_path": dest_path, "src_folders": src_folders,
                    })

            st.markdown("#### å·®åˆ†PDFä¸€è¦§ï¼ˆ1ãƒ•ã‚¡ã‚¤ãƒ«=1è¡Œï¼‰")
            if diff_rows:
                df_diff = pd.DataFrame(diff_rows).sort_values(["year", "pno", "delta", "filename"]).reset_index(drop=True)
                st.dataframe(df_diff, width="stretch", height=420)
                csv_bytes = df_diff.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "â¬‡ï¸ å·®åˆ†PDFä¸€è¦§ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_bytes,
                    file_name="pdf_differences.csv",
                    mime="text/csv",
                )
            else:
                st.info("å·®åˆ†PDFã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            st.info("å¹´ã‚’å…¥åŠ›ã—ã¦ã€â–¶ å‡ºåŠ›ã€ã‚’æŠ¼ã™ã¨ã€è©³ç´°ï¼ˆpnoåˆ¥ã¨å·®åˆ†ä¸€è¦§ï¼‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")



thick_divider("#007ACC", 4)

# ========== â‘¡ ãƒ•ã‚©ãƒ«ãƒ€å â†’ å¹´/ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·åˆ†é¡ ==========
st.subheader("â‘¡ ãƒ•ã‚©ãƒ«ãƒ€åã®åˆ†é¡ï¼ˆå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ï¼‰")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¦å‰‡ã§ã€Œå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã€ã«åˆ†é¡
    - ã“ã“ã§ **å¹´ã”ã¨ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹** ã‚’ä»˜ã‘ã¾ã—ãŸã€‚  
      âœ… ãƒã‚§ãƒƒã‚¯ã—ãŸ **å¹´** ãŒ â‘£ ã®å¯¾è±¡ã«ãªã‚Šã¾ã™ã€‚
      9999å¹´ã¯å›³æ›¸ç®¡ç†DBæ‰±ã„
    """,
    unsafe_allow_html=True
)


# â‘ ã®çµæœ rows_lvl1 ã‚’åˆ†é¡
parsed_rows: List[Dict[str, Any]] = []
for row in rows_lvl1:
    info = _parse_folder_name(row["name"])
    info["path"] = row["path"]
    parsed_rows.append(info)

# é¸æŠã•ã‚ŒãŸå¹´ã®çŠ¶æ…‹ã‚’ä¿æŒã™ã‚‹å…¥ã‚Œç‰©ï¼ˆâ‘¡ç”¨ï¼‰
if "selected_years_for_copy" not in st.session_state:
    st.session_state["selected_years_for_copy"] = set()

# å¹´ã”ã¨è¡¨ç¤ºï¼ˆå¹´ãƒ˜ãƒƒãƒ€ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼‰
if not parsed_rows:
    st.info("åˆ†é¡å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    grouped: Dict[Any, List[Dict[str, Any]]] = {}
    for item in parsed_rows:
        year = item["year"] if item["year"] is not None else "ãã®ä»–"
        grouped.setdefault(year, []).append(item)

    for year, items in sorted(grouped.items(), key=lambda x: str(x[0])):
        # å¹´ãƒ˜ãƒƒãƒ€ã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼ˆã“ã“ã§é¸ã‚“ã å¹´ã‚’ â‘£ ã«åæ˜ ï¼‰
        year_key = f"year_pick_{year}"
        init = (year in st.session_state["selected_years_for_copy"])
        picked = st.checkbox(f"ğŸ“… å¹´: {year}ï¼ˆ{len(items)} ä»¶ï¼‰", key=year_key, value=init)

        if picked:
            st.session_state["selected_years_for_copy"].add(year)
        else:
            st.session_state["selected_years_for_copy"].discard(year)

        # å¹´ã”ã¨ã®è©³ç´°ãƒªã‚¹ãƒˆã¯ expander ã§æŠ˜ã‚Šç•³ã¿
        with st.expander(f"{year} ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§", expanded=False):
            for it in sorted(items, key=lambda x: (x["pno"] if x["pno"] is not None else 999999, x["name"])):
                pn = "â€”" if it["pno"] is None else f"{it['pno']}"
                st.markdown(f"- **{it['name']}** ï½œ PNo:{pn} ã€”{it['category']}ã€•")

st.divider()


# ========== â‘¢ Library(P) â†’ å›³æ›¸ç®¡ç†DB ã§å¹´ã‚’è£œè¶³ ==========
st.subheader("â‘¢ å›³æ›¸ç®¡ç†DBã«ã‚ˆã‚‹åˆ†é¡è£œè¶³ï¼ˆLibrary(P) ãƒ•ã‚©ãƒ«ãƒ€ï¼‰")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - Library(P) ãƒ•ã‚©ãƒ«ãƒ€ â†’ å›³æ›¸ç®¡ç†DBï¼ˆExcel: Sheet1ï¼‰ã§å¹´ã‚’è£œè¶³åˆ†é¡  
    - æœ¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã‚‚ **å¹´ã”ã¨ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹** ã‚’ä»˜ã‘ã€é¸æŠçŠ¶æ…‹ã‚’ä¿å­˜ã—ã¾ã™ï¼ˆå¾Œç¶šå‡¦ç†ã¯å¾Œã§è¿½åŠ ï¼‰ã€‚  
    - ã“ã“ã§ã® **pno ã¯ã€Œç™»éŒ²ç•ªå·ã®ä¸‹3æ¡ã€** ã‚’æ¡ç”¨ã—ã¾ã™ã€‚  
    """,
    unsafe_allow_html=True
)

LIB_DB_PATH = Path(PATHS.library_root).expanduser().resolve() / "å›³æ›¸ç®¡ç†DB.xlsx"

# ç™ºè¡Œå¹´ã®æ­£è¦åŒ–
_ZEN = "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
_HAN = "0123456789"
Z2H = str.maketrans(_ZEN, _HAN)

def parse_year_field(val) -> int:
    """Excelã€ç™ºè¡Œå¹´ã€ã‹ã‚‰4æ¡å¹´ã‚’æŠ½å‡ºã€‚å¤±æ•—æ™‚ã¯ 9999ã€‚"""
    if pd.isna(val):
        return 9999
    if isinstance(val, (int, float)) and not isinstance(val, bool):
        try:
            y = int(val)
            return y if 1800 <= y <= 2100 else 9999
        except Exception:
            pass
    s = str(val).strip().translate(Z2H)
    m = re.search(r"(\d{4})", s)
    if m:
        y = int(m.group(1))
        return y if 1800 <= y <= 2100 else 9999
    return 9999

lib_parsed_rows: List[Dict[str, Any]] = []

if LIB_DB_PATH.exists():
    try:
        df_lib = pd.read_excel(
            LIB_DB_PATH, sheet_name="Sheet1",
            dtype={"ç™»éŒ²ç•ªå·": "string", "ç™ºè¡Œå¹´": "string"}
        )
        df_lib["ç™»éŒ²ç•ªå·"] = df_lib["ç™»éŒ²ç•ªå·"].astype("string").str.strip()
        df_lib["ç™ºè¡Œå¹´_norm"] = df_lib["ç™ºè¡Œå¹´"].map(parse_year_field)
        regno_to_year: Dict[str, int] = (
            df_lib[["ç™»éŒ²ç•ªå·", "ç™ºè¡Œå¹´_norm"]]
            .dropna()
            .set_index("ç™»éŒ²ç•ªå·")["ç™ºè¡Œå¹´_norm"]
            .to_dict()
        )

        # Library(P) ã¨åˆ¤å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã®ã¿å‡¦ç†
        for row in parsed_rows:
            if row["category"] != "Library(P)":
                continue
            folder_path = (REPORT_ROOT / row["path"]).resolve()
            if not folder_path.exists():
                continue

            # ãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ã® PDF ã‚’åˆ—æŒ™
            for pdf in folder_path.glob("*.pdf"):
                # ãƒ•ã‚¡ã‚¤ãƒ«åå…ˆé ­ã€Œç™»éŒ²ç•ªå·-â€¦ã€ã‹ã‚‰ç™»éŒ²ç•ªå·ã‚’æŠ½å‡º
                m = re.match(r"(\d+)-", pdf.name)
                if not m:
                    continue
                regno = m.group(1)

                # å›³æ›¸DBã‹ã‚‰ç™ºè¡Œå¹´ã‚’å¼•ãï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° 9999ï¼‰
                year = regno_to_year.get(regno, 9999)

                # â˜… pno ã¯ã€Œç™»éŒ²ç•ªå·ã®ä¸‹3æ¡ã€
                pno_last3 = 999
                if regno.isdigit():
                    pno_last3 = int(regno[-3:])

                lib_parsed_rows.append({
                    "name": pdf.name,
                    "category": "Library(P)-DB",
                    "year": year,
                    "pno": pno_last3,                        # â† ã“ã“ãŒå¤‰æ›´ç‚¹
                    "path": str(pdf.relative_to(REPORT_ROOT)),
                })

    except Exception as e:
        st.error(f"å›³æ›¸ç®¡ç†DBã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
else:
    st.warning(f"å›³æ›¸ç®¡ç†DBãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: `{LIB_DB_PATH}`")

# â‘¢ã®é¸æŠçŠ¶æ…‹ã‚’ä¿æŒï¼ˆå¹´å˜ä½ï¼‰
if "selected_years_libdb" not in st.session_state:
    st.session_state["selected_years_libdb"] = set()

# --- â‘¢ã®çµæœè¡¨ç¤ºï¼ˆå¹´ã”ã¨ã«å±•é–‹ãƒ»å¹´è¦‹å‡ºã—ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ä»˜ãï¼‰ ---
if lib_parsed_rows:
    grouped2: Dict[int, List[Dict[str, Any]]] = {}
    for item in lib_parsed_rows:
        grouped2.setdefault(item["year"], []).append(item)

    for year, items in sorted(grouped2.items(), key=lambda x: str(x[0])):
        # å¹´è¦‹å‡ºã—ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ï¼ˆçŠ¶æ…‹ã®ã¿ä¿æŒã€‚å‡¦ç†ã¯å¾Œã§è¿½åŠ ï¼‰
        key_y = f"libdb_year_pick_{year}"
        init_y = (year in st.session_state["selected_years_libdb"])
        picked_y = st.checkbox(f"ğŸ“šï¼ˆDBï¼‰å¹´: {year}ï¼ˆ{len(items)} ä»¶ï¼‰", key=key_y, value=init_y)
        if picked_y:
            st.session_state["selected_years_libdb"].add(year)
        else:
            st.session_state["selected_years_libdb"].discard(year)

        with st.expander(f"{year} ã® PDF ä¸€è¦§ï¼ˆLibraryè£œè¶³ï¼‰", expanded=False):
            for it in sorted(items, key=lambda x: (x["pno"], x["name"])):
                st.markdown(f"- **{it['name']}** ï½œ PNo:{it['pno']:03d} ã€”{it['category']}ã€•")
else:
    st.info("Library(P) ã«è©²å½“ã—ã€DBã§å¹´ãŒå¼•ã‘ãŸPDFã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

st.divider()


# ========== â‘£ â‘¡ã§é¸æŠã—ãŸå¹´ã® <å¹´>/<pno>/ ã¸ PDF ã‚³ãƒ”ãƒ¼ ==========
st.subheader("â‘£ â‘¡ã§é¸æŠã—ãŸå¹´ã®ãƒ•ã‚©ãƒ«ãƒ€ã¸ PDF ã‚³ãƒ”ãƒ¼ï¼ˆ<ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/ï¼‰")
st.markdown(
    """
    ğŸ“Œ **èª¬æ˜**  
    - â‘¡ã§ãƒã‚§ãƒƒã‚¯ã—ãŸ **å¹´** ã®ã¿ã‚’å¯¾è±¡ã«ã—ã¾ã™ã€‚  
    - å¯¾è±¡ã‚½ãƒ¼ã‚¹ã¯ã€ãã®å¹´ã® **7æ¡æ•°å€¤ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆYYYYPPP ä¾‹: 2020xxxï¼‰** ã§ã™ã€‚  
    - ã‚³ãƒ”ãƒ¼å…ˆ: `<ãƒ™ãƒ¼ã‚¹>/report/pdf/<å¹´>/<pno>/` ï¼ˆä¾‹: `ExtremeSSD/report/pdf/2020/123/`ï¼‰ã€‚  
    - æ—¢å­˜åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸Šæ›¸ãã¯ã—ãªã„ï¼‰ã€‚  
    """,
    unsafe_allow_html=True
)

# â‘¡ã§é¸ã°ã‚ŒãŸå¹´ã®è¡¨ç¤ºï¼ˆãƒãƒƒã‚¸é¢¨ï¼‰
picked_years = sorted(st.session_state.get("selected_years_for_copy", set()), key=str)
if picked_years:
    chips = " ".join([
        f"<span style='padding:2px 8px;border:1px solid #ddd;border-radius:12px;margin-right:6px;'>{y}</span>"
        for y in picked_years
    ])
    st.markdown(f"**å¯¾è±¡å¹´:** {chips}", unsafe_allow_html=True)
else:
    st.info("â‘¡ã§å¯¾è±¡å¹´ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚")

# ã‚³ãƒ”ãƒ¼å…ˆãƒ™ãƒ¼ã‚¹ï¼ˆä¾‹: ExtremeSSD/report/pdfï¼‰
# â‘£ ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…ã®å…¥åŠ›ï¼ˆæ—¢å­˜è¡Œã‚’ã“ã®1è¡Œã«ç½®æ›ï¼‰
dest_base_text = st.text_input(
    "ã‚³ãƒ”ãƒ¼å…ˆãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å®šï¼šorganized_docs_root/report/pdfï¼‰",
    value=str((Path(PATHS.organized_docs_root).expanduser().resolve() / "report" / "pdf")),
    key="dest_base_input",
)

DEST_BASE = Path(dest_base_text).expanduser().resolve()
st.caption(f"ã‚³ãƒ”ãƒ¼å…ˆãƒ™ãƒ¼ã‚¹: `{DEST_BASE}`")

def _iter_pdfs_under(folder: Path, *, ignore_hidden: bool = True) -> Iterator[Path]:
    """folder é…ä¸‹ã® PDF ã‚’å†å¸°åˆ—æŒ™ã€‚"""
    for cur, dirs, files in os.walk(folder, topdown=True, followlinks=False):
        dirs[:] = [d for d in dirs if not (ignore_hidden and d.startswith("."))]
        for fn in files:
            if ignore_hidden and fn.startswith("."):
                continue
            if fn.lower().endswith(".pdf"):
                yield Path(cur) / fn

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ“¥ â‘¡ã§é¸æŠã—ãŸå¹´ã® <å¹´>/<pno>/ ã¸ã‚³ãƒ”ãƒ¼ã‚’å®Ÿè¡Œ"):
    if not picked_years:
        st.warning("â‘¡ã§å¯¾è±¡å¹´ã‚’å°‘ãªãã¨ã‚‚1ã¤é¸ã‚“ã§ãã ã•ã„ã€‚")
    else:
        copied_total = skipped_total = errors_total = 0
        # å¹´Ã—pnoã”ã¨ã®çµ±è¨ˆ
        per_bucket_stats: Dict[str, Dict[str, int]] = {}  # key: f"{year}/{pno:03d}"

        # â‘¡ã®åˆ†é¡çµæœï¼ˆparsed_rowsï¼‰ã‹ã‚‰ã€é¸æŠå¹´ã‹ã¤ 7æ¡æ•°å€¤(YYYYPPP)ã®ã¿å‡¦ç†
        for item in parsed_rows:
            year = item.get("year")
            pno  = item.get("pno")
            name = item.get("name", "")

            # å¹´ãŒé¸æŠã•ã‚Œã¦ã„ãªã„ / å¹´ãŒæ•°å€¤ã§ãªã„å ´åˆã¯é™¤å¤–
            if year not in picked_years or not isinstance(year, int):
                continue

            # 7æ¡æ•°å€¤ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆYYYYPPPï¼‰ã ã‘å¯¾è±¡
            if not re.fullmatch(rf"^{year}\d{{3}}$", name):
                continue

            # pno ãŒå–ã‚Œãªã„ã‚±ãƒ¼ã‚¹ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç†è«–ä¸Š numeric7 ãªã‚‰ 3æ¡ï¼‰
            if pno is None:
                continue

            # ã‚½ãƒ¼ã‚¹ãƒ»ãƒ‡ã‚¹ãƒ†ã‚£ãƒãƒ¼ã‚·ãƒ§ãƒ³
            src_dir = (REPORT_ROOT / item["path"]).resolve()
            dest_dir = (DEST_BASE / str(year) / f"{int(pno):03d}").resolve()  # ä¾‹: .../2020/123/
            dest_dir.mkdir(parents=True, exist_ok=True)

            bucket_key = f"{year}/{int(pno):03d}"
            per_bucket_stats.setdefault(bucket_key, {"copied": 0, "skipped": 0, "errors": 0})

            for src in _iter_pdfs_under(src_dir):
                dest = dest_dir / src.name
                try:
                    if dest.exists():
                        skipped_total += 1
                        per_bucket_stats[bucket_key]["skipped"] += 1
                    else:
                        shutil.copy2(src, dest)  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¶­æŒ
                        copied_total += 1
                        per_bucket_stats[bucket_key]["copied"] += 1
                except Exception:
                    errors_total += 1
                    per_bucket_stats[bucket_key]["errors"] += 1

        # ã‚µãƒãƒª
        c1, c2, c3 = st.columns(3)
        c1.metric("Copied (total)", copied_total)
        c2.metric("Skipped (total)", skipped_total)
        c3.metric("Errors (total)", errors_total)

        # å¹´/pnoã”ã¨ã®å†…è¨³
        if per_bucket_stats:
            df_bucket = pd.DataFrame(
                [{"year_pno": y, **stat} for y, stat in sorted(per_bucket_stats.items(), key=lambda x: x[0])]
            )
            st.dataframe(df_bucket, width="stretch", height=260)
        else:
            st.info("å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
