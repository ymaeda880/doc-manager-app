# pages/20_reportæ•´ç†.py
# ============================================
# ğŸ“‚ report æ•´ç†ï¼ˆoriginal_docs_root/report é…ä¸‹ã®ä¸€è¦§ï¼‰
# - â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§
# - â‘¡ ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¦å‰‡ã§ã€Œå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã€ã«åˆ†é¡
# - â‘¢ Library(P) ãƒ•ã‚©ãƒ«ãƒ€ â†’å›³æ›¸ç®¡ç†DBï¼ˆSheet1ï¼‰ã§å¹´ã‚’è£œè¶³åˆ†é¡
# - â‘£ 2019xxx ãƒ•ã‚©ãƒ«ãƒ€ â†’ organized_docs_root/2019/xxx ã¸ PDF ã‚³ãƒ”ãƒ¼
# ============================================

from __future__ import annotations
from pathlib import Path
from typing import Iterator, Dict, Any, List
import os
import re
import shutil
import datetime as dt

import streamlit as st
import pandas as pd

from lib.app_paths import PATHS
from lib.fsnav.scan import iter_dirs, safe_stat_mtime, listdir_counts

# ä»»æ„ï¼šPDFã®è»½é‡ç¨®åˆ¥
try:
    from lib.pdf.info import quick_pdf_info  # æœªä½¿ç”¨ã§ã‚‚OK
except Exception:
    quick_pdf_info = None


# ========== ãƒšãƒ¼ã‚¸è¨­å®š ==========
st.set_page_config(page_title="report æ•´ç†", page_icon="ğŸ“‚", layout="wide")
st.title("ğŸ“‚ report æ•´ç† â€” original_docs_root/report é…ä¸‹ã®ä¸€è¦§")

# ========== èµ·ç‚¹ ==========
ROOT_BASE = Path(str(PATHS.original_docs_root)).expanduser().resolve()
REPORT_ROOT_DEFAULT = ROOT_BASE / "report"
report_text = st.text_input("report ã®å®Ÿãƒ‘ã‚¹ï¼ˆå¤‰æ›´ä¸è¦ãªã‚‰æ—¢å®šã®ã¾ã¾ï¼‰", value=str(REPORT_ROOT_DEFAULT))
REPORT_ROOT = Path(report_text).expanduser().resolve()

if not REPORT_ROOT.exists():
    st.error("original_docs_root/report ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚PATHS ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ========== ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==========
with st.sidebar:
    st.header("è¨­å®š")
    st.caption(f"å®Ÿãƒ‘ã‚¹: `{REPORT_ROOT}`")
    c = st.columns(2)
    with c[0]:
        ignore_hidden = st.checkbox("éš ã—ãƒ•ã‚©ãƒ«ãƒ€ã‚’é™¤å¤–", value=True)
    with c[1]:
        compute_counts = st.checkbox("ç›´ä¸‹ã®ä»¶æ•°ã‚’è¨ˆç®—", value=False)
    st.divider()
    st.subheader("â‘  ãƒ•ã‚£ãƒ«ã‚¿")
    name_filter = st.text_input("åç§°ã®éƒ¨åˆ†ä¸€è‡´ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ï¼‰", value="").strip()


# ========== â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ ==========
st.subheader("â‘  æ·±ã•1ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§ï¼ˆreport ç›´ä¸‹ï¼‰")
rows_lvl1: List[Dict[str, Any]] = []
level1_paths: List[Path] = []

for d in iter_dirs(REPORT_ROOT, max_depth=1, ignore_hidden=ignore_hidden):
    level1_paths.append(d)
    nm = d.name
    if name_filter and (name_filter.lower() not in nm.lower()):
        continue
    mtime = safe_stat_mtime(d)
    fcnt, dcnt = listdir_counts(d) if compute_counts else (None, None)
    rows_lvl1.append({
        "path": str(d.relative_to(REPORT_ROOT)),
        "name": nm,
        "depth": 1,
        "modified": dt.datetime.fromtimestamp(mtime) if mtime else None,
        "files_direct": fcnt,
        "dirs_direct": dcnt,
    })

if rows_lvl1:
    df1 = pd.DataFrame(rows_lvl1).sort_values("path")
    st.dataframe(df1, width="stretch", height=300)
else:
    st.info("ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

st.divider()


# ========== â‘¡ ãƒ•ã‚©ãƒ«ãƒ€å â†’ å¹´/ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·åˆ†é¡ ==========
st.subheader("â‘¡ ãƒ•ã‚©ãƒ«ãƒ€åã®åˆ†é¡ï¼ˆå¹´ / ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ï¼‰")

def _parse_folder_name(name: str) -> Dict[str, Any]:
    # (i) 7æ¡: YYYYPPP
    m = re.fullmatch(r"(\d{4})(\d{3})", name)
    if m:
        return {"name": name, "category": "numeric7", "year": int(m[1]), "pno": int(m[2])}
    # (ii) Heisei: HNNPPP
    m = re.fullmatch(r"H(\d{2})(\d{3})", name, re.I)
    if m:
        return {"name": name, "category": "Heisei", "year": 1988 + int(m[1]), "pno": int(m[2])}
    # (iii) Showa: SNNPPP
    m = re.fullmatch(r"S(\d{2})(\d{3})", name, re.I)
    if m:
        return {"name": name, "category": "Showa", "year": 1925 + int(m[1]), "pno": int(m[2])}
    # (iv) P*
    if re.match(r"^P", name, re.I):
        return {"name": name, "category": "Library(P)", "year": 9999, "pno": 999}
    # (v) ãã®ä»–
    return {"name": name, "category": "other", "year": None, "pno": None}

parsed_rows: List[Dict[str, Any]] = []
for row in rows_lvl1:
    info = _parse_folder_name(row["name"])
    info["path"] = row["path"]
    parsed_rows.append(info)

if not parsed_rows:
    st.info("åˆ†é¡å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    grouped = {}
    for item in parsed_rows:
        year = item["year"] if item["year"] is not None else "ãã®ä»–"
        grouped.setdefault(year, []).append(item)

    for year, items in sorted(grouped.items(), key=lambda x: str(x[0])):
        with st.expander(f"ğŸ“… å¹´: {year}ï¼ˆ{len(items)} ä»¶ï¼‰", expanded=False):
            for it in sorted(items, key=lambda x: (x["pno"] if x["pno"] is not None else 999999, x["name"])):
                pn = "â€”" if it["pno"] is None else f"{it['pno']}"
                st.markdown(f"- **{it['name']}** ï½œ PNo:{pn} ã€”{it['category']}ã€•")

st.divider()


# ========== â‘¢ Library(P) â†’å›³æ›¸ç®¡ç†DB ã§å¹´ã‚’è£œè¶³ ==========
st.subheader("â‘¢å›³æ›¸ç®¡ç†DBã«ã‚ˆã‚‹åˆ†é¡è£œè¶³ï¼ˆLibrary(P) ãƒ•ã‚©ãƒ«ãƒ€ï¼‰")

LIB_DB_PATH = Path(PATHS.library_root).expanduser().resolve() / "å›³æ›¸ç®¡ç†DB.xlsx"

# --- ç™ºè¡Œå¹´ã®æ­£è¦åŒ–ãƒ˜ãƒ«ãƒ‘ ---
_ZEN = "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
_HAN = "0123456789"
Z2H = str.maketrans(_ZEN, _HAN)

def parse_year_field(val) -> int:
    """Excelã®ã€ç™ºè¡Œå¹´ã€ã‹ã‚‰è¥¿æš¦4æ¡ã‚’æŠ½å‡ºã€‚è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° 9999ã€‚"""
    if pd.isna(val):
        return 9999
    # æ•°å€¤ãªã‚‰ãã®ã¾ã¾æ•´æ•°åŒ–ï¼ˆ1981.0 â†’ 1981ï¼‰
    if isinstance(val, (int, float)) and not isinstance(val, bool):
        try:
            y = int(val)
            return 1900 <= y <= 2100 and y or 9999
        except Exception:
            pass
    # æ–‡å­—åˆ—å‡¦ç†
    s = str(val).strip()
    if not s:
        return 9999
    # å…¨è§’æ•°å­—â†’åŠè§’
    s = s.translate(Z2H)
    # å…ˆé ­ã«ç¾ã‚Œã‚‹4æ¡ã®æ•°å­—ã‚’å¹´ã¨ã—ã¦æ¡ç”¨ï¼ˆ1981/3, 1977.2, 1980-81 ãªã©ï¼‰
    m = re.search(r"(\d{4})", s)
    if m:
        y = int(m.group(1))
        return 1800 <= y <= 2100 and y or 9999
    return 9999

lib_parsed_rows: List[Dict[str, Any]] = []

if LIB_DB_PATH.exists():
    try:
        # dtype=str ã§èª­ã¿ã€ç™»éŒ²ç•ªå·/ç™ºè¡Œå¹´ã‚’æ–‡å­—åˆ—ã§å®‰å®šåŒ–
        df_lib = pd.read_excel(
            LIB_DB_PATH,
            sheet_name="Sheet1",
            dtype={"ç™»éŒ²ç•ªå·": "string", "ç™ºè¡Œå¹´": "string"}
        )

        # å‰å‡¦ç†ï¼šç™»éŒ²ç•ªå·â†’ç™ºè¡Œå¹´(æ­£è¦åŒ–) ã® dict
        df_lib["ç™»éŒ²ç•ªå·"] = df_lib["ç™»éŒ²ç•ªå·"].astype("string").str.strip()
        df_lib["ç™ºè¡Œå¹´_norm"] = df_lib["ç™ºè¡Œå¹´"].map(parse_year_field)
        regno_to_year: Dict[str, int] = (
            df_lib[["ç™»éŒ²ç•ªå·", "ç™ºè¡Œå¹´_norm"]]
            .dropna()
            .set_index("ç™»éŒ²ç•ªå·")["ç™ºè¡Œå¹´_norm"]
            .to_dict()
        )

        # Library(P) ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‡¦ç†
        for row in parsed_rows:
            if row["category"] != "Library(P)":
                continue
            folder_path = (REPORT_ROOT / row["path"]).resolve()
            if not folder_path.exists():
                continue

            # Pãƒ•ã‚©ãƒ«ãƒ€åã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·
            try:
                pno = int(row["name"].lstrip("Pp"))
            except Exception:
                pno = 999

            # ãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ã®PDFã®ã¿å¯¾è±¡ï¼ˆå¿…è¦ãªã‚‰å†å¸°ã«å¤‰æ›´å¯ï¼‰
            for pdf in folder_path.glob("*.pdf"):
                m = re.match(r"(\d+)-", pdf.name)  # å…ˆé ­ã€Œç•ªå·-â€¦ã€å½¢å¼
                if not m:
                    continue
                regno = m.group(1)

                year = regno_to_year.get(regno, 9999)
                lib_parsed_rows.append({
                    "name": pdf.name,
                    "category": "Library(P)-DB",
                    "year": year,
                    "pno": pno,
                    "path": str(pdf.relative_to(REPORT_ROOT)),
                })

    except Exception as e:
        st.error(f"å›³æ›¸ç®¡ç†DBã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
else:
    st.warning(f"å›³æ›¸ç®¡ç†DBãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: `{LIB_DB_PATH}`")

# è¡¨ç¤º
if lib_parsed_rows:
    grouped = {}
    for item in lib_parsed_rows:
        grouped.setdefault(item["year"], []).append(item)
    for year, items in sorted(grouped.items(), key=lambda x: str(x[0])):
        with st.expander(f"ğŸ“… å¹´: {year}ï¼ˆ{len(items)} ä»¶ / Libraryè£œè¶³ï¼‰", expanded=False):
            for it in sorted(items, key=lambda x: (x["pno"], x["name"])):
                st.markdown(f"- **{it['name']}** ï½œ PNo:{it['pno']} ã€”{it['category']}ã€•")
else:
    st.info("Library(P) ã«è©²å½“ã—ã€DBã§å¹´ãŒå¼•ã‘ãŸPDFã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

st.divider()


# ========== â‘£ 2019xxx â†’ organized_docs_root ã¸ã‚³ãƒ”ãƒ¼ ==========
st.subheader("â‘£ 2019 å¹´ã®å„ä¸‹3æ¡ãƒ•ã‚©ãƒ«ãƒ€ã¸ PDF ã‚³ãƒ”ãƒ¼ï¼ˆorganized_docs_root/2019/xyzï¼‰")

dest_base_text = st.text_input(
    "ã‚³ãƒ”ãƒ¼å…ˆãƒ™ãƒ¼ã‚¹ï¼ˆæ—¢å®šï¼šorganized_docs_rootï¼‰",
    value=str(Path(PATHS.organized_docs_root).expanduser().resolve())
)
ORG_BASE = Path(dest_base_text)
ORGYEAR = ORG_BASE / "2019"
PAT_2019 = re.compile(r"^2019(\d{3})$")

def _iter_pdfs_under(folder: Path, *, ignore_hidden=True) -> Iterator[Path]:
    for cur, dirs, files in os.walk(folder, topdown=True, followlinks=False):
        curp = Path(cur)
        # éš ã—é™¤å¤–
        dirs[:] = [d for d in dirs if not (ignore_hidden and d.startswith("."))]
        for fn in files:
            if ignore_hidden and fn.startswith("."):
                continue
            if fn.lower().endswith(".pdf"):
                yield curp / fn

if st.button("ğŸ“¥ 2019/ä¸‹3æ¡ ã¸ã‚³ãƒ”ãƒ¼ã‚’å®Ÿè¡Œ"):
    copied = skipped = errors = 0
    for row in rows_lvl1:
        m = PAT_2019.match(row["name"])
        if not m:
            continue
        last3 = m.group(1)
        src_dir = REPORT_ROOT / row["path"]
        dest_subdir = ORGYEAR / last3
        dest_subdir.mkdir(parents=True, exist_ok=True)
        for src in _iter_pdfs_under(src_dir):
            dest = dest_subdir / src.name
            try:
                if dest.exists():
                    skipped += 1
                else:
                    shutil.copy2(src, dest)
                    copied += 1
            except Exception:
                errors += 1

    c1, c2, c3 = st.columns(3)
    c1.metric("Copied", copied)
    c2.metric("Skipped", skipped)
    c3.metric("Errors", errors)
