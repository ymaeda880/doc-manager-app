# pages/15_SSDãƒ“ãƒ¥ãƒ¼ã‚¢.py
# =============================================================================
# ğŸ“‚ SSDãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆé‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ’é™¤ã—ãŸPDFé›†è¨ˆãƒ»æ¯”è¼ƒãƒ„ãƒ¼ãƒ«ï¼‰
# -----------------------------------------------------------------------------
# æ¦‚è¦:
#  1) ORIGINAL_DOCS_ROOT/report/ ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã‚’è¦å‰‡ã«æ²¿ã£ã¦è§£é‡ˆã—ã€å¹´ä»£â†’å¹´â†’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é–²è¦§
#  2) é¸æŠã—ãŸå¹´ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ DataFrame ã§æ‹¡å¼µå­åˆ¥é›†è¨ˆï¼ˆâ˜…åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯1å›ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆï¼‰
#  3) ORGANIZED_DOCS_ROOT å´ï¼ˆreport/pdf, report_skip/pdfï¼‰ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã«é›†è¨ˆã—ã¦è¡¨ç¤º
#  4) å¹´å†…ã®å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã—ã¦ã€original ã® .pdf ç·æ•° ã¨ organizedï¼ˆreport+report_skipï¼‰ã®åˆè¨ˆã‚’
#     ç…§åˆã—ã€ä¸ä¸€è‡´ãŒã‚ã‚Œã°è­¦å‘Šï¼ˆâ˜…åŒåPDFé‡è¤‡ã¯æ’é™¤ã€ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚‚å†å¸°ï¼‰
#  5) å¹´ãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã‚’æŒ‡å®šã—ã¦å€‹åˆ¥ã« original / organized ã‚’æ¯”è¼ƒã™ã‚‹UIã‚‚æä¾›
#
# é‡è¦:
#  - ã€ŒåŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯ 1 å›ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆã€ã€‚ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã«åŒã˜åå‰ãŒã‚ã£ã¦ã‚‚é‡è¤‡ã¨ã—ã¦æ’é™¤
#  - organized å´ã§ã¯ *_ocr.pdf ã¯é€šå¸¸ PDF ã¨ã—ã¦æ•°ãˆã‚‹ã€‚*_skip.pdf ã¯ã€Œskipã€ã¨ã—ã¦åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
#  - original å´ã¯ç´”ç²‹ãª .pdf ã®ã¿ã‚’å¯¾è±¡ï¼ˆåŒåé™¤å¤–ãƒ»ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å«ã‚€ï¼‰
# =============================================================================

import streamlit as st
from pathlib import Path
import re
from collections import defaultdict
import pandas as pd
import sys

# ------------------------------------------------------------
# ãƒ‘ã‚¹è¨­å®š
# ------------------------------------------------------------
from lib.app_paths import PATHS

ORIGINAL_DOCS_ROOT = Path(getattr(PATHS, "original_docs_root")).expanduser().resolve()
ORGANIZED_DOCS_ROOT = getattr(PATHS, "organized_docs_root", None)

if not ORIGINAL_DOCS_ROOT.exists():
    st.error(f"{ORIGINAL_DOCS_ROOT} ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒã‚¦ãƒ³ãƒˆã‚„è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

ROOT = ORIGINAL_DOCS_ROOT  # æœ¬ç”»é¢ã§ã¯ original ã‚’åŸºç‚¹ã«èµ°æŸ»

# ------------------------------------------------------------
# UIãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆä»»æ„ï¼‰
# ------------------------------------------------------------
PROJECTS_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECTS_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECTS_ROOT))
try:
    from common_lib.ui.ui_basics import thick_divider
except Exception:
    def thick_divider(color="Blue", height=3, margin="1.5em 0"):
        st.markdown(f'<hr style="border:none;border-top:{height}px solid #3b82f6;margin:{margin};" />', unsafe_allow_html=True)

# ------------------------------------------------------------
# ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆãƒ‘ã‚¹æƒ…å ±ï¼‰
# ------------------------------------------------------------
st.title("ğŸ“‚ SSDãƒ“ãƒ¥ã‚¢ãƒ¼")
st.subheader("ğŸ“‚ ãƒ‘ã‚¹æƒ…å ±")

st.markdown(
    f"""
    <div style="
        background-color:#eef6fb;
        border-left: 5px solid #5fa3e0;
        padding:10px 15px;
        border-radius:8px;
        font-size:14px;
        line-height:1.6;
    ">
        <b>ROOT:</b> {ROOT}<br>
        <b>ORIGINAL_DOCS_ROOT:</b> {ORIGINAL_DOCS_ROOT}<br>
        <b>ORGANIZED_DOCS_ROOT:</b> {ORGANIZED_DOCS_ROOT or '(å¾Œã§ä½¿ç”¨)'}
    </div>
    """,
    unsafe_allow_html=True,
)

# =============================================================================
# ğŸ“¦ ã‚«ã‚¦ãƒ³ãƒˆç³»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆâ˜…åŒåãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡æ’é™¤ï¼‰
# =============================================================================
def count_unique_exts_recursive(dirpath: Path) -> dict:
    """
    dirpath é…ä¸‹ï¼ˆå­ãƒ»å­«å«ã‚€ï¼‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‹¡å¼µå­åˆ¥ã«é›†è¨ˆã€‚
    â˜…åŒåãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹: åŒå.pdfï¼‰ãŒè¤‡æ•°ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã£ã¦ã‚‚ 1 å›ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆã€‚
    """
    from collections import defaultdict
    counts = defaultdict(int)
    if not dirpath or not dirpath.exists():
        return {}
    seen_names = set()
    for f in dirpath.rglob("*"):
        if not f.is_file():
            continue
        name_lower = f.name.lower()
        if name_lower in seen_names:
            continue
        seen_names.add(name_lower)
        ext = f.suffix.lower().lstrip('.') or '(noext)'
        counts[ext] += 1
    return dict(counts)


def count_pdf_categories(dirpath: Path) -> dict:
    """
    organized / original ã„ãšã‚Œã§ã‚‚ä½¿ãˆã‚‹ PDF åˆ†é¡ã‚«ã‚¦ãƒ³ãƒˆï¼ˆâ˜…åŒåæ’é™¤ï¼‰ã€‚
      - 'pdf'       : é€šå¸¸PDF + *_ocr.pdf ã‚’ä¸€æ‹¬ã§ã‚«ã‚¦ãƒ³ãƒˆï¼ˆ*_skip.pdf ã¯é™¤å¤–ï¼‰
      - 'skip_pdf'  : *_skip.pdf
      - 'ocr_pdf'   : *_ocr.pdf
      - 'side_json' : *_side.json
    """
    counts = {"pdf": 0, "skip_pdf": 0, "ocr_pdf": 0, "side_json": 0}
    if not dirpath or not dirpath.exists():
        return counts
    seen_names = set()
    for f in dirpath.rglob("*"):
        if not f.is_file():
            continue
        name = f.name.lower()
        if name in seen_names:
            continue
        seen_names.add(name)
        if name.endswith("_side.json"):
            counts["side_json"] += 1
        elif name.endswith("_skip.pdf"):
            counts["skip_pdf"] += 1
        elif name.endswith("_ocr.pdf"):
            counts["ocr_pdf"] += 1
            # counts["pdf"] += 1
        elif name.endswith(".pdf"):
            counts["pdf"] += 1
    return counts

# =============================================================================
# ğŸ“˜ original/report ã®ãƒ•ã‚©ãƒ«ãƒ€å‘½åè¦å‰‡ã®è§£é‡ˆãƒ»èµ°æŸ»
# =============================================================================
def parse_folder_name(name: str):
    """ãƒ•ã‚©ãƒ«ãƒ€åã‚’è¦å‰‡ã§è§£æã—ã¦ (ç¨®åˆ¥, â€¦) ã‚’è¿”ã™ã€‚"""
    s = name.strip()
    if s.upper().startswith("P"):
        return ("library", s)
    if re.fullmatch(r"\d{7}", s):
        return ("year", int(s[:4]), int(s[4:]))  # YYYYPPP
    m = re.fullmatch(r"H(\d{2})(\d{3})", s, re.IGNORECASE)
    if m:
        return ("year", 1988 + int(m.group(1)), int(m.group(2)))
    m = re.fullmatch(r"S(\d{2})(\d{3})", s, re.IGNORECASE)
    if m:
        return ("year", 1925 + int(m.group(1)), int(m.group(2)))
    return ("other", s)

@st.cache_data(show_spinner=False)
def scan_report_dirs(report_dir: Path):
    """
    original/report é…ä¸‹ç›´ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’èµ°æŸ»ã—ã€
    å¹´â†’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã®å¯¾å¿œã€ãŠã‚ˆã³ (year, pno) â†’ Path ã‚’è¿”ã™ã€‚
    """
    years_to_pnos = defaultdict(set)
    proj_dir_map = {}
    library_names, others = [], []

    if not report_dir.exists():
        return years_to_pnos, proj_dir_map, library_names, others

    for p in report_dir.iterdir():
        if not p.is_dir():
            continue
        kind = parse_folder_name(p.name)
        if kind[0] == "year":
            _, year, pno = kind
            years_to_pnos[year].add(pno)
            proj_dir_map.setdefault((year, pno), p)
        elif kind[0] == "library":
            library_names.append(kind[1])
        else:
            others.append(kind[1])

    for y in list(years_to_pnos.keys()):
        years_to_pnos[y] = sorted(years_to_pnos[y])

    return years_to_pnos, proj_dir_map, sorted(set(library_names)), sorted(set(others))

REPORT_DIR = ORIGINAL_DOCS_ROOT / "report"
years_to_pnos, proj_dir_map, library_names, others = scan_report_dirs(REPORT_DIR)

# =============================================================================
# ğŸ§® DataFrameãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆé‡è¤‡æ’é™¤ï¼‰
# =============================================================================
PREFERRED_COLS = [
    "pdf","doc","docx","xls","xlsx","xlsm","ppt","pptx",
    "csv","txt","xml","json","md","jpg","jpeg","png","gif",
    "tif","tiff","svg","ai","psd","indd","dtd","p21","mcd","(noext)"
]

def build_df_from_pairs(pairs: list[tuple[str, Path]]) -> pd.DataFrame:
    """
    pairs: [(project_display, project_dir), ...]
    return: æ‹¡å¼µå­åˆ¥ã‚«ã‚¦ãƒ³ãƒˆã‚’è¡Œã£ãŸ DataFrameï¼ˆåˆ—é †æ•´å½¢æ¸ˆï¼‰
    â˜…åŒåãƒ•ã‚¡ã‚¤ãƒ«ã¯æ’é™¤ã—ãŸé›†è¨ˆã‚’ä½¿ç”¨
    """
    rows, all_exts = [], set()
    for proj, pdir in pairs:
        counts = count_unique_exts_recursive(pdir)
        all_exts.update(counts.keys())
        rows.append({"project": proj, "total": sum(counts.values()), **counts})
    if not rows:
        return pd.DataFrame()

    dynamic = [e for e in sorted(all_exts) if e not in PREFERRED_COLS]
    columns = ["project", "total"] + [e for e in PREFERRED_COLS if e in all_exts] + dynamic
    df = pd.DataFrame(rows).reindex(columns=columns, fill_value=0).sort_values("project")
    return df

# =============================================================================
# ğŸ“Š organized å´ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤ºï¼ˆreport/pdf, report_skip/pdfï¼‰
# =============================================================================
def render_organized_year_section(title: str, base_dir: Path, year: int):
    """
    organized å´ã®å¹´ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼é…ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ‹¡å¼µå­åˆ¥é›†è¨ˆï¼ˆåŒåæ’é™¤ï¼‰ã—ã¦è¡¨ç¤ºã€‚
    base_dir: Path(ORGANIZED_DOCS_ROOT) / "report" / "pdf" ãªã©
    """
    st.divider()
    note = " ï¼ˆåˆ†æã‹ã‚‰æ’é™¤ã—ã¦ã„ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼‰" if "report_skip" in title else ""
    st.markdown(f"**{title}/{year} ã®é›†è¨ˆ{note}**")

    if not ORGANIZED_DOCS_ROOT:
        st.info("ORGANIZED_DOCS_ROOT ãŒæœªè¨­å®šã§ã™ã€‚")
        return

    year_dir = base_dir / str(year)
    if not year_dir.exists():
        st.info(f"å¹´ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {year_dir}")
        return

    proj_dirs = sorted([p for p in year_dir.iterdir() if p.is_dir()], key=lambda x: x.name)
    st.caption("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·: " + (", ".join([p.name for p in proj_dirs]) if proj_dirs else "ï¼ˆãªã—ï¼‰"))

    pairs = [(d.name, d) for d in proj_dirs]
    df = build_df_from_pairs(pairs)
    if df.empty:
        st.info("ï¼ˆè©²å½“ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãªã—ï¼‰")
    else:
        st.dataframe(df, width='stretch')
        st.download_button(
            label=f"CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{title}ï¼‰",
            data=df.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"{year}_{title.replace('/','_')}_ext_counts.csv",
            mime="text/csv",
        )

# =============================================================================
# ğŸ§­ å¹´ä»£ â†’ å¹´ â†’ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ UI
# =============================================================================
DECADES = [
    ("1970å¹´ä»£", 1970, 1979),
    ("1980å¹´ä»£", 1980, 1989),
    ("1990å¹´ä»£", 1990, 1999),
    ("2000å¹´ä»£", 2000, 2009),
    ("2010å¹´ä»£", 2010, 2019),
    ("2020å¹´ä»£", 2020, 2099),
]
RADIO_LABELS = [d[0] for d in DECADES] + ["å›³æ›¸é¤¨", "ãã®ä»–"]

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠï¼šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æœ€åˆã®å¹´ä»£ â†’ å›³æ›¸é¤¨ â†’ ãã®ä»–
default_idx, found = 0, False
for i, (_, y0, y1) in enumerate(DECADES):
    if any(y0 <= y <= y1 for y in years_to_pnos.keys()):
        default_idx = i
        found = True
        break
if not found and library_names:
    default_idx = len(DECADES)
elif not found and others:
    default_idx = len(DECADES) + 1

thick_divider(color="Blue", height=3, margin="1.5em 0")
st.subheader("å¹´ä»£ / å›³æ›¸é¤¨ / ãã®ä»– ã‚’é¸æŠ")
selected = st.radio("è¡¨ç¤ºã‚«ãƒ†ã‚´ãƒª", RADIO_LABELS, index=default_idx, horizontal=True)

# =============================================================================
# ğŸ–¼ è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
# =============================================================================
if selected == "å›³æ›¸é¤¨":
    st.markdown("**å›³æ›¸é¤¨ï¼ˆP...ï¼‰ã®ãƒ•ã‚©ãƒ«ãƒ€ä¸€è¦§**")
    st.info(", ".join(library_names) or "å›³æ›¸é¤¨ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

elif selected == "ãã®ä»–":
    st.markdown("**ãã®ä»–ï¼ˆå‘½åè¦å‰‡ã«å½“ã¦ã¯ã¾ã‚‰ãªã„ãƒ•ã‚©ãƒ«ãƒ€ï¼‰**")
    st.info(", ".join(others) or "ãã®ä»–ã®ãƒ•ã‚©ãƒ«ãƒ€ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

else:
    # å¹´ä»£ã®ç¯„å›²å–å¾—
    for label, a, b in DECADES:
        if label == selected:
            y0, y1 = a, b
            break
    years_in_decade = sorted(y for y in years_to_pnos if y0 <= y <= y1)

    st.markdown(f"**{selected} ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§**")
    if not years_in_decade:
        st.info("è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # å¹´ã”ã¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ä¸€è¦§ï¼ˆè¦–è¦šæ•´å½¢ï¼‰
        lines = [f"{y}å¹´ï¼š " + ", ".join(f"{n:03d}" for n in years_to_pnos[y]) for y in years_in_decade]
        html_lines = "<br>".join(f"<b>{line.split('ï¼š')[0]}ï¼š</b>{line.split('ï¼š')[1]}" for line in lines)
        st.markdown(
            f"""
            <div style="
                background-color:#eef6fb;
                border-left:5px solid #5fa3e0;
                padding:12px 18px;
                border-radius:8px;
                font-size:14px;
                line-height:1.8;
                color:#002b55;
            ">
                {"<br><br>".join(html_lines.split("<br>"))}
            </div>
            """,
            unsafe_allow_html=True,
        )

        # --- å¹´ãƒ©ã‚¸ã‚ªï¼ˆå¹´ä»£å†…ã®å¹´ã‹ã‚‰é¸æŠï¼‰ ---
        st.divider()
        year_options = [y for y in years_in_decade]
        if year_options:
            chosen_year_label = st.radio(
                "å¹´ã‚’é¸æŠ",
                options=[f"{y}å¹´" for y in year_options],
                index=0,  # æœ€åˆã®å¹´ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
                horizontal=True,
                key="year_radio_in_decade",
            )
            chosen_year = int(chosen_year_label[:-1])  # "1973å¹´" -> 1973

            # ========== original å´ï¼šé¸æŠå¹´ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ‹¡å¼µå­åˆ¥é›†è¨ˆï¼ˆåŒåæ’é™¤ï¼‰ ==========
            pairs_original = [
                (f"{pno:03d}", proj_dir_map.get((chosen_year, pno)))
                for pno in years_to_pnos.get(chosen_year, [])
                if proj_dir_map.get((chosen_year, pno)) is not None
            ]
            df_original = build_df_from_pairs(pairs_original)
            st.markdown(f"**{chosen_year}å¹´ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆï¼ˆæ‹¡å¼µå­åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•°, original/reportï¼‰**")
            if df_original.empty:
                st.info("ï¼ˆè©²å½“ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãªã—ï¼‰")
            else:
                st.dataframe(df_original, width='stretch')
                st.download_button(
                    label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆoriginal/reportï¼‰",
                    data=df_original.to_csv(index=False).encode("utf-8-sig"),
                    file_name=f"{chosen_year}_original_report_ext_counts.csv",
                    mime="text/csv",
                )

            # ========== organized å´ï¼šreport/pdf/<å¹´> ã¨ report_skip/pdf/<å¹´> ==========
            if ORGANIZED_DOCS_ROOT:
                render_organized_year_section(
                    "organized/report/pdf", Path(ORGANIZED_DOCS_ROOT) / "report" / "pdf", chosen_year
                )
                render_organized_year_section(
                    "organized/report_skip/pdf", Path(ORGANIZED_DOCS_ROOT) / "report_skip" / "pdf", chosen_year
                )
            else:
                st.info("ORGANIZED_DOCS_ROOT ãŒæœªè¨­å®šã§ã™ã€‚")

            # =============================================================================
            # ğŸ” å¹´å†…ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆoriginal vs organizedï¼‰
            # -----------------------------------------------------------------------------
            # originalç·æ•° = original/report/<YYYYPPP> å†…ã® .pdfï¼ˆåŒåé™¤å¤–ï¼‰
            # organizedç·æ•° = organized/(report/pdf + report_skip/pdf) å†…ã®
            #                 ï¼ˆ.pdf + *_skip.pdfã€*_ocr.pdfã¯pdfã«å«ã‚ãªã„ï¼åŒåé™¤å¤–ï¼‰
            # â†’ ä¸€è‡´ã—ãªã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è­¦å‘Š
            # =============================================================================
            from itertools import chain

            # å¹´å†…ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé›†åˆã‚’ç¶²ç¾…
            projects_original = {f"{pno:03d}" for pno in years_to_pnos.get(chosen_year, [])}
            org_report_year_dir      = Path(ORGANIZED_DOCS_ROOT) / "report"      / "pdf" / str(chosen_year) if ORGANIZED_DOCS_ROOT else None
            org_report_skip_year_dir = Path(ORGANIZED_DOCS_ROOT) / "report_skip" / "pdf" / str(chosen_year) if ORGANIZED_DOCS_ROOT else None
            projects_org_report      = {p.name for p in org_report_year_dir.iterdir()      if org_report_year_dir      and p.is_dir()} if ORGANIZED_DOCS_ROOT and org_report_year_dir      and org_report_year_dir.exists()      else set()
            projects_org_report_skip = {p.name for p in org_report_skip_year_dir.iterdir() if org_report_skip_year_dir and p.is_dir()} if ORGANIZED_DOCS_ROOT and org_report_skip_year_dir and org_report_skip_year_dir.exists() else set()

            all_projects = sorted(projects_original | projects_org_report | projects_org_report_skip)

            rows_chk = []
            for proj in all_projects:
                # original å´ï¼ˆåŒåPDFæ’é™¤ï¼‰
                pdir_original = proj_dir_map.get((chosen_year, int(proj))) if proj.isdigit() else None
                original_count = 0
                if pdir_original:
                    seen = set()
                    for f in pdir_original.rglob("*"):
                        if f.is_file() and f.suffix.lower() == ".pdf":
                            name = f.name.lower()
                            if name in seen: 
                                continue
                            seen.add(name)
                            original_count += 1

                # organized å´ï¼ˆåŒåPDFæ’é™¤ã€_ocrã¯pdfã«å«ã‚ãªã„ï¼‰
                b = c = d = e = 0
                if ORGANIZED_DOCS_ROOT:
                    # report/pdf/<year>/<proj>
                    rp = (org_report_year_dir / proj) if org_report_year_dir else None
                    if rp and rp.exists():
                        cc = count_pdf_categories(rp)
                        b = cc["pdf"]       # é€šå¸¸pdfï¼ˆ_ocré™¤å¤–, _skipé™¤å¤–ï¼‰
                        c = cc["skip_pdf"]  # *_skip.pdf
                    # report_skip/pdf/<year>/<proj>
                    rps = (org_report_skip_year_dir / proj) if org_report_skip_year_dir else None
                    if rps and rps.exists():
                        cc2 = count_pdf_categories(rps)
                        d = cc2["pdf"]
                        e = cc2["skip_pdf"]

                org_report_sum      = b + c
                org_report_skip_sum = d + e
                organized_count     = org_report_sum + org_report_skip_sum
                match_flag          = (original_count == organized_count)

                rows_chk.append({
                    "ãƒã‚§ãƒƒã‚¯çµæœ": "âœ…ä¸€è‡´" if match_flag else "âš ï¸ä¸ä¸€è‡´",
                    "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ": proj,
                    "originalç·æ•°": original_count,
                    "organized(report)": org_report_sum,
                    "organized(report_skip)": org_report_skip_sum,
                    "organizedç·æ•°": organized_count,
                })

            df_chk = pd.DataFrame(rows_chk).sort_values("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ")

            thick_divider(color="Blue", height=3, margin="1.5em 0")
            st.subheader("ğŸ” æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆoriginal vs organizedï¼‰")
            st.caption(f"å¯¾è±¡å¹´ï¼š{chosen_year}å¹´")  # â† å¹´ã‚’è¡¨ç¤º
            st.dataframe(df_chk, width='stretch')

            # ä¸ä¸€è‡´ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’è­¦å‘Š
            mismatched = df_chk[df_chk["ãƒã‚§ãƒƒã‚¯çµæœ"] == "âš ï¸ä¸ä¸€è‡´"]["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"].tolist()
            if mismatched:
                st.warning(
                    "original ã® .pdf ç·æ•° ã¨ organized ã®åˆè¨ˆãŒä¸€è‡´ã—ãªã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒã‚ã‚Šã¾ã™ï¼š"
                    + ", ".join(mismatched)
                )

            # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                label="CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼‰",
                data=df_chk.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{chosen_year}_consistency_check.csv",
                mime="text/csv",
            )

            # =============================================================================
            # ğŸ§® å€‹åˆ¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¢ºèªï¼ˆyear + pno ã‚’æŒ‡å®šã—ã¦é›†è¨ˆï¼‰â€” åŒåæ’é™¤
            # =============================================================================
            st.divider()
            st.subheader("ğŸ§® å€‹åˆ¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç¢ºèª")

            col1, col2, col3 = st.columns([1, 1, 1])
            with col1:
                input_year = st.text_input("å¹´ï¼ˆä¾‹: 2015ï¼‰", value=str(chosen_year))
            with col2:
                input_pno = st.text_input("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ï¼ˆä¾‹: 123ï¼‰", value="")
            with col3:
                run_check = st.button("é›†è¨ˆ")

            if run_check and input_year.isdigit() and input_pno.isdigit():
                y_val = int(input_year)
                p_val = int(input_pno)

                # original å´ï¼šYYYYPPP ã§ãƒ‘ã‚¹ã‚’ç›´æ¥æŒ‡ã™ï¼ˆè¦å‰‡ã«ä¸€è‡´ã—ã¦ã„ã‚Œã°å­˜åœ¨ï¼‰
                pdir_original_direct = Path(ORIGINAL_DOCS_ROOT) / "report" / f"{y_val}{p_val:03d}"
                orig_counts = count_pdf_categories(pdir_original_direct)
                orig_total = orig_counts["pdf"]

                # organized å´
                counts_report = count_pdf_categories(
                    Path(ORGANIZED_DOCS_ROOT or "") / "report" / "pdf" / str(y_val) / f"{p_val:03d}"
                )
                counts_report_skip = count_pdf_categories(
                    Path(ORGANIZED_DOCS_ROOT or "") / "report_skip" / "pdf" / str(y_val) / f"{p_val:03d}"
                )

                b, c = counts_report["pdf"], counts_report["skip_pdf"]
                d, e = counts_report_skip["pdf"], counts_report_skip["skip_pdf"]
                org_total = b + c + d + e

                df_single = pd.DataFrame([{
                    "year": y_val,
                    "project": f"{p_val:03d}",
                    "originalç·æ•°": orig_total,
                    "organizedç·æ•°": org_total,
                    "report(pdf)": b,
                    "report(_skip.pdf)": c,
                    "report_skip(pdf)": d,
                    "report_skip(_skip.pdf)": e,
                    "ä¸€è‡´": "âœ…ä¸€è‡´" if orig_total == org_total else "âš ï¸ä¸ä¸€è‡´"
                }])

                st.dataframe(df_single, width='stretch')

                if orig_total == org_total:
                    st.success("âœ… original ã¨ organized ã®PDFç·æ•°ã¯ä¸€è‡´ã—ã¦ã„ã¾ã™ã€‚")
                else:
                    st.error("âš ï¸ original ã¨ organized ã®PDFç·æ•°ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")

            elif run_check:
                st.warning("å¹´ã¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç•ªå·ã¯æ•°å€¤ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
